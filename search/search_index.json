{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Grape Docs Welcome to grape documentation and coder good practices. We are leaving some links, our productive process description, UI standards code snippets, NET Core CRUD code snippets and more. All Must Read and Watch this Sets of videos of uncle bob about considerations of how to code, better than any Netflix production, you should watch this!. https://www.youtube.com/playlist?list=PLmmYSbUCWJ4x1GO839azG_BBw8rkh-zOj","title":"Home"},{"location":"#grape-docs","text":"Welcome to grape documentation and coder good practices. We are leaving some links, our productive process description, UI standards code snippets, NET Core CRUD code snippets and more.","title":"Grape Docs"},{"location":"#all-must-read-and-watch-this","text":"Sets of videos of uncle bob about considerations of how to code, better than any Netflix production, you should watch this!. https://www.youtube.com/playlist?list=PLmmYSbUCWJ4x1GO839azG_BBw8rkh-zOj","title":"All Must Read and Watch this"},{"location":"angular/","text":"Angular Proyectos de angular ng new PROYECT Ejecutar los comandos para el linter ng add @angular-eslint/schematics ng g @angular-eslint/schematics:convert-tslint-to-eslint si es microfront ng add @angular-architects/module-federation Componentes comunes npm i bootstrap npm i ngx-toastr npm i @fortawesome/angular-fontawesome npm i @fortawesome/free-solid-svg-icons npm i ngx-pagination npm i ngx-bootstrap Configurar angular.js \"node_modules/bootstrap/dist/js/bootstrap.bundle.min.js\" y \"node_modules/bootstrap/scss/bootstrap.scss\", \"node_modules/ngx-toastr/toastr.css\", Copiar: auth.guard.ts http-token.interceptor.ts Configurar en app.module.ts imports: [ BrowserModule, FormsModule, AppRoutingModule, FontAwesomeModule, BrowserAnimationsModule, // CommonModule, RouterModule.forRoot(routes), ToastrModule.forRoot({ timeOut: 3000, positionClass: 'toast-bottom-right', preventDuplicates: true, }), ModalModule.forRoot(), HttpClientModule, TabsModule.forRoot(), // NgxPaginationModule, // TooltipModule.forRoot(), BsDropdownModule.forRoot(), ], providers: [{ provide: HTTP_INTERCEPTORS, useClass: TokenInterceptor, multi: true }], Agregar routes export const routes: Routes = [ { path: '', redirectTo: 'noti', pathMatch: 'full', }, { path: 'noti', loadChildren: () => import('./notificaciones/notificaciones.module').then((m) => m.NotificacionesModule), }, { path: 'login', component: LoginMfeComponent, }, Copiar services helper uy auth para login-mfe Acomodar app.component.html <div class=\"container\"> <router-outlet></router-outlet> </div> Multi idiomas ng add @angular/localize https://angular.io/guide/i18n-overview Agregar a los componentes que necesiten ser traducidos -> para no repetir se puede armar una lista de los Ids en el proyecto y los textos que traducen angular.js En el tag ProjecName agregar: \"i18n\": { \"sourceLocale\":\"es\", --> es el idioma default \"locales\":{ \"en\":\"src/locale/messages.en.json\" } } en el tag architect:build:options agregar: \"localize\":true --> para que compile en todos los idiomas o \"localize\":[\"es\"] --> para que compile en un idioma predeterminado En architect:build:configurations agregar: \"es\":{ \"localize\":\"es\" }, \"en\":{ \"localize\":\"en\" } en architect:serve:configurations agregar: \"es\":{ \"browserTarget\":\"core:build:es\" }, \"en\":{ \"browserTarget\":\"core:build:en\" } package.json Se deber\u00e1 ajustar para que cuando se haga el serve o el build lo haga considerando el multi idioma. Cada vez que se agregue un TAG i18n o $localize en los TS se deber\u00e1 correr el npm run extract-i18n para reconstruir el messages.json sino tirar\u00e1 un warning que falta una traducci\u00f3n. en scripts agregar: \"start-es\":\"ng serve --configuration=es\", \"start-en\":\"ng serve --configuration=en\", \"extract-i18n\":\"ng extract-i18n --format=json --output-pat src/locale\", --> esto deja el archivo messages.json que despues hay que pasarlo al ingles copiandolo messages.en.json ejemplos de c\u00f3digo multi idioma En los m\u00f3dulos para que funcione el $localize es necesario importar: import '@angular/localize/init' Hay que agregar en providers del/los m\u00f3dulos {provide: LOCALE_ID, useValue:'es'} en los archivos TS los string que deban ser traducidos se sacan as\u00ed $localize :@@UniqueTextId:cadena a traducir ${VARIABLE SI NECESITO CONCATENAR ALGO} en los archivos HTML -> para no repetir se puede armar una lista de los Ids en el proyecto y los textos que traducen Uso de Observables Un observable por lo general se define en la capa de servicios cuando se comparte entre diferentes componentes: private objectSubject: BehaviorSubject<any>; public object$: Observable<any>; En el servicio se realizan operaciones que actualizan el privado y tienen que ejecutar el .next (este evento es el que notifica a los suscriptores) Login(identifier?: string, password?: string) { return this.http .post(`${environment.apiUrl}/auth/login`, { Identifier: identifier, Password: password, }) .pipe( tap((authResp: any) => { localStorage.setItem('user', JSON.stringify(authResp)); this.userSubject.next(localUser); }), ); } Por ultimo queda suscribirse a los observable desde los componentes, esto se realiza de distintas formas: Si es en el template hay que avisar que son async <div class=\"d-md-flex justify-content-md-end\" *ngIf=\"(inscripcionOferta$ | async).length\"> <li class=\"list-group-item border-bottom py-0\" *ngFor=\"let inscripcion of items$ | async\"> Si es en el TS se crea en objeto local y la suscripci\u00f3n. Se suscribe al inicio y se desuscribe al destroy, esto es muy importante. user: any; userSub: Subscription; ngOnInit(): void { this.userSub = this.authService.user$.subscribe((u) => { if (u != null && u.userID) { this.isLoggedIn = true; } else { this.isLoggedIn = false; } this.user = u; }); } ngOnDestroy(): void { this.userSub.unsubscribe(); }","title":"Angular"},{"location":"angular/#angular","text":"Proyectos de angular ng new PROYECT Ejecutar los comandos para el linter ng add @angular-eslint/schematics ng g @angular-eslint/schematics:convert-tslint-to-eslint si es microfront ng add @angular-architects/module-federation Componentes comunes npm i bootstrap npm i ngx-toastr npm i @fortawesome/angular-fontawesome npm i @fortawesome/free-solid-svg-icons npm i ngx-pagination npm i ngx-bootstrap Configurar angular.js \"node_modules/bootstrap/dist/js/bootstrap.bundle.min.js\" y \"node_modules/bootstrap/scss/bootstrap.scss\", \"node_modules/ngx-toastr/toastr.css\", Copiar: auth.guard.ts http-token.interceptor.ts Configurar en app.module.ts imports: [ BrowserModule, FormsModule, AppRoutingModule, FontAwesomeModule, BrowserAnimationsModule, // CommonModule, RouterModule.forRoot(routes), ToastrModule.forRoot({ timeOut: 3000, positionClass: 'toast-bottom-right', preventDuplicates: true, }), ModalModule.forRoot(), HttpClientModule, TabsModule.forRoot(), // NgxPaginationModule, // TooltipModule.forRoot(), BsDropdownModule.forRoot(), ], providers: [{ provide: HTTP_INTERCEPTORS, useClass: TokenInterceptor, multi: true }], Agregar routes export const routes: Routes = [ { path: '', redirectTo: 'noti', pathMatch: 'full', }, { path: 'noti', loadChildren: () => import('./notificaciones/notificaciones.module').then((m) => m.NotificacionesModule), }, { path: 'login', component: LoginMfeComponent, }, Copiar services helper uy auth para login-mfe Acomodar app.component.html <div class=\"container\"> <router-outlet></router-outlet> </div>","title":"Angular"},{"location":"angular/#multi-idiomas","text":"ng add @angular/localize https://angular.io/guide/i18n-overview Agregar a los componentes que necesiten ser traducidos -> para no repetir se puede armar una lista de los Ids en el proyecto y los textos que traducen","title":"Multi idiomas"},{"location":"angular/#angularjs","text":"En el tag ProjecName agregar: \"i18n\": { \"sourceLocale\":\"es\", --> es el idioma default \"locales\":{ \"en\":\"src/locale/messages.en.json\" } } en el tag architect:build:options agregar: \"localize\":true --> para que compile en todos los idiomas o \"localize\":[\"es\"] --> para que compile en un idioma predeterminado En architect:build:configurations agregar: \"es\":{ \"localize\":\"es\" }, \"en\":{ \"localize\":\"en\" } en architect:serve:configurations agregar: \"es\":{ \"browserTarget\":\"core:build:es\" }, \"en\":{ \"browserTarget\":\"core:build:en\" }","title":"angular.js"},{"location":"angular/#packagejson","text":"Se deber\u00e1 ajustar para que cuando se haga el serve o el build lo haga considerando el multi idioma. Cada vez que se agregue un TAG i18n o $localize en los TS se deber\u00e1 correr el npm run extract-i18n para reconstruir el messages.json sino tirar\u00e1 un warning que falta una traducci\u00f3n. en scripts agregar: \"start-es\":\"ng serve --configuration=es\", \"start-en\":\"ng serve --configuration=en\", \"extract-i18n\":\"ng extract-i18n --format=json --output-pat src/locale\", --> esto deja el archivo messages.json que despues hay que pasarlo al ingles copiandolo messages.en.json","title":"package.json"},{"location":"angular/#ejemplos-de-codigo-multi-idioma","text":"En los m\u00f3dulos para que funcione el $localize es necesario importar: import '@angular/localize/init' Hay que agregar en providers del/los m\u00f3dulos {provide: LOCALE_ID, useValue:'es'} en los archivos TS los string que deban ser traducidos se sacan as\u00ed $localize :@@UniqueTextId:cadena a traducir ${VARIABLE SI NECESITO CONCATENAR ALGO} en los archivos HTML -> para no repetir se puede armar una lista de los Ids en el proyecto y los textos que traducen","title":"ejemplos de c\u00f3digo multi idioma"},{"location":"angular/#uso-de-observables","text":"Un observable por lo general se define en la capa de servicios cuando se comparte entre diferentes componentes: private objectSubject: BehaviorSubject<any>; public object$: Observable<any>; En el servicio se realizan operaciones que actualizan el privado y tienen que ejecutar el .next (este evento es el que notifica a los suscriptores) Login(identifier?: string, password?: string) { return this.http .post(`${environment.apiUrl}/auth/login`, { Identifier: identifier, Password: password, }) .pipe( tap((authResp: any) => { localStorage.setItem('user', JSON.stringify(authResp)); this.userSubject.next(localUser); }), ); } Por ultimo queda suscribirse a los observable desde los componentes, esto se realiza de distintas formas: Si es en el template hay que avisar que son async <div class=\"d-md-flex justify-content-md-end\" *ngIf=\"(inscripcionOferta$ | async).length\"> <li class=\"list-group-item border-bottom py-0\" *ngFor=\"let inscripcion of items$ | async\"> Si es en el TS se crea en objeto local y la suscripci\u00f3n. Se suscribe al inicio y se desuscribe al destroy, esto es muy importante. user: any; userSub: Subscription; ngOnInit(): void { this.userSub = this.authService.user$.subscribe((u) => { if (u != null && u.userID) { this.isLoggedIn = true; } else { this.isLoggedIn = false; } this.user = u; }); } ngOnDestroy(): void { this.userSub.unsubscribe(); }","title":"Uso de Observables"},{"location":"autocomplete/","text":"How to implement Angular Autocomplete Html Component Code <input type=\"search\" autocomplete=\"off\" typeaheadOptionField=\"fullName\" [(ngModel)]=\"term\" [typeahead]=\"suggestions$\" [typeaheadAsync]=\"true\" (typeaheadOnSelect)=\"onSelect($event)\" [typeaheadWaitMs]=\"500\" (keyup)=\"onKeyUp()\" (ngModelChange)=\"onKeyUp()\" class=\"form-control\" placeholder=\"XXXXX\" /> TS Component Code import { Component, EventEmitter, Input, OnInit, Output } from '@angular/core'; import { TypeaheadMatch } from 'ngx-bootstrap/typeahead'; import { Observable, Observer, map, noop, of, switchMap, tap } from 'rxjs'; import { HelperService } from '../services/helper.service'; import { UtilsService } from '../services/utils.service'; @Component({ selector: 'app-country-autocomplete', templateUrl: './country-autocomplete.component.html', styles: [], }) export class CountryAutocompleteComponent implements OnInit { @Input() term: string = ''; @Input() selected: any = {}; @Output() selectedChange = new EventEmitter(); working = false; suggestions$: Observable<any[]>; constructor(private baseServices: UtilsService, private helpers: HelperService) {} ngOnInit(): void { this.suggestions$ = new Observable((observer: Observer<any>) => { observer.next(this.term); }).pipe( switchMap((query: string) => { if (query) { return this.baseServices.searchCountriesAutocomplete({ searchText: query }).pipe( map((data: any) => (data && data) || []), tap({ next: () => noop, error: (e) => { // in case of http error this.helpers.RaiseNotification('danger', 'Error', e.error ?? e.message); }, }), ); } return of([]); }), ); } onKeyUp(): void { if (this.term?.length === 0) { this.selected = null; this.selectedChange.emit(''); } } onSelect(event: TypeaheadMatch): void { this.selected = event.item; this.selectedChange.emit(this.selected.countriesID); } }","title":"Autocomplete"},{"location":"autocomplete/#how-to-implement-angular-autocomplete","text":"","title":"How to implement Angular Autocomplete"},{"location":"autocomplete/#html","text":"Component Code <input type=\"search\" autocomplete=\"off\" typeaheadOptionField=\"fullName\" [(ngModel)]=\"term\" [typeahead]=\"suggestions$\" [typeaheadAsync]=\"true\" (typeaheadOnSelect)=\"onSelect($event)\" [typeaheadWaitMs]=\"500\" (keyup)=\"onKeyUp()\" (ngModelChange)=\"onKeyUp()\" class=\"form-control\" placeholder=\"XXXXX\" />","title":"Html"},{"location":"autocomplete/#ts","text":"Component Code import { Component, EventEmitter, Input, OnInit, Output } from '@angular/core'; import { TypeaheadMatch } from 'ngx-bootstrap/typeahead'; import { Observable, Observer, map, noop, of, switchMap, tap } from 'rxjs'; import { HelperService } from '../services/helper.service'; import { UtilsService } from '../services/utils.service'; @Component({ selector: 'app-country-autocomplete', templateUrl: './country-autocomplete.component.html', styles: [], }) export class CountryAutocompleteComponent implements OnInit { @Input() term: string = ''; @Input() selected: any = {}; @Output() selectedChange = new EventEmitter(); working = false; suggestions$: Observable<any[]>; constructor(private baseServices: UtilsService, private helpers: HelperService) {} ngOnInit(): void { this.suggestions$ = new Observable((observer: Observer<any>) => { observer.next(this.term); }).pipe( switchMap((query: string) => { if (query) { return this.baseServices.searchCountriesAutocomplete({ searchText: query }).pipe( map((data: any) => (data && data) || []), tap({ next: () => noop, error: (e) => { // in case of http error this.helpers.RaiseNotification('danger', 'Error', e.error ?? e.message); }, }), ); } return of([]); }), ); } onKeyUp(): void { if (this.term?.length === 0) { this.selected = null; this.selectedChange.emit(''); } } onSelect(event: TypeaheadMatch): void { this.selected = event.item; this.selectedChange.emit(this.selected.countriesID); } }","title":"TS"},{"location":"b4to5/","text":"Bootstrap 4 to 5 migration replace on HTML General Reemplazar las clases mr- x me- y las clases ml- por ms- buscador d-flex justify-content-between input-group x d-flex justify-content-between float-right x float-end badge badge-info x badge text-bg-info selects -> form-control x checkbox -> se agrega en el input class=\"form-check-input\" modals -> close pull-right x btn-close, modal-title pull-left x modal-title, quitar \u00d7 ABM row flex-row-reverse mt-4 x d-flex flex-row-reverse mt-4 mr-2 x me-2 (as\u00ed con todos los m se reemplaza rxe y lxs)","title":"Bootstrap 4 to 5"},{"location":"b4to5/#bootstrap-4-to-5-migration","text":"replace on HTML","title":"Bootstrap 4 to 5 migration"},{"location":"b4to5/#general","text":"Reemplazar las clases mr- x me- y las clases ml- por ms-","title":"General"},{"location":"b4to5/#buscador","text":"d-flex justify-content-between input-group x d-flex justify-content-between float-right x float-end badge badge-info x badge text-bg-info selects -> form-control x checkbox -> se agrega en el input class=\"form-check-input\" modals -> close pull-right x btn-close, modal-title pull-left x modal-title, quitar \u00d7","title":"buscador"},{"location":"b4to5/#abm","text":"row flex-row-reverse mt-4 x d-flex flex-row-reverse mt-4 mr-2 x me-2 (as\u00ed con todos los m se reemplaza rxe y lxs)","title":"ABM"},{"location":"environment-dev/","text":"Configuraci\u00f3n del Envirnoment de Dev en digital ocean Comandos utiles Para creaci\u00f3n de los certifcados con Letscrypt y nginx crear el archivo sudo nginx -t sudo certbot --nginx -d domain.sandbox.ar sudo systemctl status nginx Entornos activados Auth Macro url: UBA Posgrado url: Notificaciones Boldt url: Neox Acento url:","title":"Environment Dev"},{"location":"environment-dev/#configuracion-del-envirnoment-de-dev-en-digital-ocean","text":"","title":"Configuraci\u00f3n del Envirnoment de Dev en digital ocean"},{"location":"environment-dev/#comandos-utiles","text":"Para creaci\u00f3n de los certifcados con Letscrypt y nginx crear el archivo sudo nginx -t sudo certbot --nginx -d domain.sandbox.ar sudo systemctl status nginx","title":"Comandos utiles"},{"location":"environment-dev/#entornos-activados","text":"","title":"Entornos activados"},{"location":"environment-dev/#auth-macro","text":"url:","title":"Auth Macro"},{"location":"environment-dev/#uba-posgrado","text":"url:","title":"UBA Posgrado"},{"location":"environment-dev/#notificaciones-boldt","text":"url:","title":"Notificaciones Boldt"},{"location":"environment-dev/#neox-acento","text":"url:","title":"Neox Acento"},{"location":"http-services/","text":"Calling external REST In each Microservice some times calling others REST is needed. In that case this are the steps to implement this kind of calls. Startup or Program Simple version is not using a custom handler to intercept HTTP Calls in this case this is the code. services.AddHttpClient<SimpleRouteService>(); LoginHandler is not needed, only should exists if for some reason use case need to log or define some general params, or for debug. This code should be replace with correct params. services.AddTransient<LoggingHandler>(); services.AddHttpClient<SimpleRouteService>() // Only if capture each request is required as Angular Interceptor .AddHttpMessageHandler<LoggingHandler>(); If token integration is fixed it should be record in database SystemIntegrations and token params should be get from there, same as URL. This params should be added in service constructor. Class LoggingHandler is needed, you must copy it from other microservice. Http Service SDK Each service should be implemented throw a user class with this format. public class SimpleRouteService { private readonly HttpClient _httpClient; private readonly AppDBContext db; /// <summary> /// Constructor is executing only once when app starts /// </summary> /// <param name=\"httpClient\"></param> /// <param name=\"httpContextAccessor\"></param> public SimpleRouteService(HttpClient httpClient, IHttpContextAccessor httpContextAccessor, AppDBContext context) { db = context; _httpClient = httpClient; var integrations = GetOrCreateSystemIntegration(\"SimpleRoute\").Result; httpClient.BaseAddress = new Uri(integrations.UrlLogin); // Get params from database SystemIntegrations httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Token\", integrations.Token); httpClient.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(\"application/json\")); } public async Task<dynamic> GetMe() { var responseString = await _httpClient.GetStringAsync(\"/v1/accounts/me/\"); var res = JsonConvert.DeserializeObject<dynamic>(responseString); return res; } private async Task<SystemIntegration> GetOrCreateSystemIntegration(string appName) { var integration = await db.SystemsIntegrations.FirstOrDefaultAsync(x=>x.AppName == appName); if(integration == null) { integration = new SystemIntegration{ AppName = appName, Token = \"XXXXXXX\", Protocol = \"apikey\", Active = true, UrlLogin = \"https://api.simpliroute.com/\", }; await db.SystemsIntegrations.AddAsync(integration); await db.SaveChangesAsync(); } return integration; } } Developer should implement each method and each class used in this file. Controllers Where is need to call external REST this code should be write. protected readonly SimpleRouteService _routeClient; And in constructor public PedidosController(AppDBContext context, SimpleRouteService route) : base(context) { _routeClient = route; } Then each time a call is needed a private object is available in controller.","title":"External Services"},{"location":"http-services/#calling-external-rest","text":"In each Microservice some times calling others REST is needed. In that case this are the steps to implement this kind of calls.","title":"Calling external REST"},{"location":"http-services/#startup-or-program","text":"Simple version is not using a custom handler to intercept HTTP Calls in this case this is the code. services.AddHttpClient<SimpleRouteService>(); LoginHandler is not needed, only should exists if for some reason use case need to log or define some general params, or for debug. This code should be replace with correct params. services.AddTransient<LoggingHandler>(); services.AddHttpClient<SimpleRouteService>() // Only if capture each request is required as Angular Interceptor .AddHttpMessageHandler<LoggingHandler>(); If token integration is fixed it should be record in database SystemIntegrations and token params should be get from there, same as URL. This params should be added in service constructor. Class LoggingHandler is needed, you must copy it from other microservice.","title":"Startup or Program"},{"location":"http-services/#http-service-sdk","text":"Each service should be implemented throw a user class with this format. public class SimpleRouteService { private readonly HttpClient _httpClient; private readonly AppDBContext db; /// <summary> /// Constructor is executing only once when app starts /// </summary> /// <param name=\"httpClient\"></param> /// <param name=\"httpContextAccessor\"></param> public SimpleRouteService(HttpClient httpClient, IHttpContextAccessor httpContextAccessor, AppDBContext context) { db = context; _httpClient = httpClient; var integrations = GetOrCreateSystemIntegration(\"SimpleRoute\").Result; httpClient.BaseAddress = new Uri(integrations.UrlLogin); // Get params from database SystemIntegrations httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Token\", integrations.Token); httpClient.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(\"application/json\")); } public async Task<dynamic> GetMe() { var responseString = await _httpClient.GetStringAsync(\"/v1/accounts/me/\"); var res = JsonConvert.DeserializeObject<dynamic>(responseString); return res; } private async Task<SystemIntegration> GetOrCreateSystemIntegration(string appName) { var integration = await db.SystemsIntegrations.FirstOrDefaultAsync(x=>x.AppName == appName); if(integration == null) { integration = new SystemIntegration{ AppName = appName, Token = \"XXXXXXX\", Protocol = \"apikey\", Active = true, UrlLogin = \"https://api.simpliroute.com/\", }; await db.SystemsIntegrations.AddAsync(integration); await db.SaveChangesAsync(); } return integration; } } Developer should implement each method and each class used in this file.","title":"Http Service SDK"},{"location":"http-services/#controllers","text":"Where is need to call external REST this code should be write. protected readonly SimpleRouteService _routeClient; And in constructor public PedidosController(AppDBContext context, SimpleRouteService route) : base(context) { _routeClient = route; } Then each time a call is needed a private object is available in controller.","title":"Controllers"},{"location":"linter/","text":"Configuring ESLint on Angular Test on A14 copiar los archivos o el contendido de la carpeta ESLint ng add @angular-eslint/schematics ng g @angular-eslint/schematics:convert-tslint-to-eslint copiar el directorio ESLint al directorio del proyecto Packages devDependencies @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser @typescript-eslint/eslint-plugin @typescript-eslint/parser eslint import-sort import-sort-cli import-sort-parser-typescript import-sort-style-module vscode extensions { \"recommendations\": [ \"amatiasq.sort-imports\", \"DSKWRK.vscode-generate-getter-setter\", \"esbenp.prettier-vscode\", \"johnpapa.vscode-peacock\", \"ms-azuretools.vscode-docker\", \"ms-vscode.vscode-typescript-tslint-plugin\", \"PKief.material-icon-theme\", \"expertly-simple.ng-evergreen\", \"formulahendry.auto-close-tag\", \"HookyQR.beautify\", \"johnpapa.angular-essentials\", \"msjsdiag.debugger-for-edge\" ] } vscode settings \u00b4\u00b4\u00b4\u00b4 { \"debug.openExplorerOnEnd\": true, \"editor.tabSize\": 2, \"editor.rulers\": [120], \"editor.autoIndent\": \"full\", \"editor.cursorBlinking\": \"solid\", \"editor.formatOnType\": false, \"editor.formatOnPaste\": false, \"editor.formatOnSave\": true, \"editor.minimap.enabled\": false, \"editor.codeActionsOnSave\": { \"source.organizeImports\": true, \"source.fixAll.tslint\": true }, \"editor.defaultFormatter\": \"esbenp.prettier-vscode\", \"[html]\": { \"editor.defaultFormatter\": \"esbenp.prettier-vscode\" }, \"[typescript]\": { \"editor.defaultFormatter\": \"esbenp.prettier-vscode\" }, \"explorer.openEditors.visible\": 0, \"files.trimTrailingWhitespace\": true, \"files.autoSave\": \"off\", \"git.confirmSync\": false, \"git.enableSmartCommit\": true, \"typescript.tsdk\": \"node_modules/typescript/lib\", \"workbench.iconTheme\": \"material-icon-theme\", \"auto-close-tag.SublimeText3Mode\": true, \"html.autoClosingTags\": true, \"ng-evergreen.upgradeChannel\": \"Latest\" } \u00b4\u00b4\u00b4\u00b4 Eslint ignore File .eslintignore \u00b4\u00b4\u00b4\u00b4 node_modules dist \u00b4\u00b4\u00b4\u00b4 eslintrc.json Internacionalizaci\u00f3n ng add @angular/localize Agregar en angular.json \"projects\": { \"my-angular-project\": { \"i18n\": { \"sourceLocale\": \"es-AR\" } } }","title":"Linter Config"},{"location":"linter/#configuring-eslint-on-angular","text":"Test on A14 copiar los archivos o el contendido de la carpeta ESLint ng add @angular-eslint/schematics ng g @angular-eslint/schematics:convert-tslint-to-eslint copiar el directorio ESLint al directorio del proyecto","title":"Configuring ESLint on Angular"},{"location":"linter/#packages-devdependencies","text":"@angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser @typescript-eslint/eslint-plugin @typescript-eslint/parser eslint import-sort import-sort-cli import-sort-parser-typescript import-sort-style-module","title":"Packages devDependencies"},{"location":"linter/#vscode-extensions","text":"{ \"recommendations\": [ \"amatiasq.sort-imports\", \"DSKWRK.vscode-generate-getter-setter\", \"esbenp.prettier-vscode\", \"johnpapa.vscode-peacock\", \"ms-azuretools.vscode-docker\", \"ms-vscode.vscode-typescript-tslint-plugin\", \"PKief.material-icon-theme\", \"expertly-simple.ng-evergreen\", \"formulahendry.auto-close-tag\", \"HookyQR.beautify\", \"johnpapa.angular-essentials\", \"msjsdiag.debugger-for-edge\" ] }","title":"vscode extensions"},{"location":"linter/#vscode-settings","text":"\u00b4\u00b4\u00b4\u00b4 { \"debug.openExplorerOnEnd\": true, \"editor.tabSize\": 2, \"editor.rulers\": [120], \"editor.autoIndent\": \"full\", \"editor.cursorBlinking\": \"solid\", \"editor.formatOnType\": false, \"editor.formatOnPaste\": false, \"editor.formatOnSave\": true, \"editor.minimap.enabled\": false, \"editor.codeActionsOnSave\": { \"source.organizeImports\": true, \"source.fixAll.tslint\": true }, \"editor.defaultFormatter\": \"esbenp.prettier-vscode\", \"[html]\": { \"editor.defaultFormatter\": \"esbenp.prettier-vscode\" }, \"[typescript]\": { \"editor.defaultFormatter\": \"esbenp.prettier-vscode\" }, \"explorer.openEditors.visible\": 0, \"files.trimTrailingWhitespace\": true, \"files.autoSave\": \"off\", \"git.confirmSync\": false, \"git.enableSmartCommit\": true, \"typescript.tsdk\": \"node_modules/typescript/lib\", \"workbench.iconTheme\": \"material-icon-theme\", \"auto-close-tag.SublimeText3Mode\": true, \"html.autoClosingTags\": true, \"ng-evergreen.upgradeChannel\": \"Latest\" } \u00b4\u00b4\u00b4\u00b4","title":"vscode settings"},{"location":"linter/#eslint-ignore","text":"File .eslintignore \u00b4\u00b4\u00b4\u00b4 node_modules dist \u00b4\u00b4\u00b4\u00b4","title":"Eslint ignore"},{"location":"linter/#eslintrcjson","text":"","title":"eslintrc.json"},{"location":"linter/#internacionalizacion","text":"ng add @angular/localize Agregar en angular.json \"projects\": { \"my-angular-project\": { \"i18n\": { \"sourceLocale\": \"es-AR\" } } }","title":"Internacionalizaci\u00f3n"},{"location":"logs/","text":"Implementing backend logs in c Framework We use serilog as default framework for our microservices. The package needed are: Serilog.AspNetCore Serilog.Enrichers.Environment Serilog.Exceptions Serilog.Exceptions.EntityFrameworkCore Serilog.Settings.Configuration Serilog.Sinks.Debug SQL Server Logs For use on SQL Server you need to add this package: Serilog.Sinks.MSSqlServer You can create a table for each microservice or define only one table and record all logs. PostgreSQL Logs For use on PostgreSQL you need to add this packages: Serilog.Sinks.PostgreSQL Serilog.Sinks.PostgreSQL.Configuration Configuration We use configuration on appsettings.json for default or in environment if you need to change some parameter in production to catch a bug. We use some aditionals fields to log information for our microservices: Elapsed: API call time consumed StatusCode: API call status code response Version: Compilation version from csproj RequestMethod: API call method RequestPath: API call endpoint Authorization: JWT sended Host: API call URL Protocol: API call protocol Scheme: API call scheme The following fields are used to know state of call and it are disabled for default throw SaveLogBodies=true appsettings param: QueryString: API call query string with key value information RequestBody: API call request body ResponseBody: API call response body Appsettings.json This is an example on how to setup default configuration to log in production. \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Error\", \"Override\": { \"Microsoft\": \"Error\", \"Microsoft.AspNetCore\": \"Error\", \"Serilog.AspNetCore\": \"Error\", \"Microsoft.EntityFrameworkCore\":\"Error\" } } This is only recording errors on all namespaces and setting some overrides nodes that you can change to get more specific information if error happend or you need to test performance. In MinimumLevel Override Each node defines a Namespace and particulary a Log Level to configure. Supouse you need to check time consuming on APIs calls, you can set Serilog.AspNetCore to Information; or maybe you need yo view the query setting Microsoft.EntityFrameworkCore to Information. SQL Configuration This is the default configuration for SQL Server on each microservice project. \"WriteTo\": [ { \"Name\": \"MSSqlServer\", \"Args\": { \"connectionString\": \"Default\", \"tableName\": \"Logs\", \"autoCreateSqlTable\": true, \"logEventFormatter\": \"Serilog.Formatting.Compact.CompactJsonFormatter, Serilog.Formatting.Compact\", \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"columnOptionsSection\": { \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"addStandardColumns\": [\"LogEvent\"], \"logEvent\": { \"excludeAdditionalProperties\": true, \"excludeStandardColumns\": true }, \"customColumns\": [ { \"ColumnName\": \"Elapsed\", \"DataType\": \"float\" }, { \"ColumnName\": \"StatusCode\", \"DataType\": \"int\" }, { \"ColumnName\": \"Version\", \"DataType\": \"varchar\", \"DataLength\": 50 }, { \"ColumnName\": \"RequestMethod\", \"DataType\": \"varchar\", \"DataLength\": 10 }, { \"ColumnName\": \"RequestPath\", \"DataType\": \"varchar\", \"DataLength\": 300 }, { \"ColumnName\": \"Authorization\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Host\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Protocol\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Scheme\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"QueryString\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"RequestBody\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"ResponseBody\", \"DataType\": \"varchar\" } ] } } } ] The key that can be changed here are: connectionString: it points to database configuration attribute define in ConnectionStrings node. tableName: is the table name where all serillog events are saved. The default is Logs but if you need to change it for debug propouse, you could change this name and save records on other table. Enrich our logs There are differents ways to enrich our event with information that help us to know service status. We can log incoming calls throw a middleware or throw a custom EnrichFromRequest method. Middleware allows to control in depth request call and method is call before executing request so response data is not available yet. Incoming API calls We use a custom middleware ApiLogMiddleware class to enrich our API calls. This allows to get context information and add it to serilog event for recording in database in Invoke method. This middleware is set in our startup process and is important the order. app.UseSerilogRequestLogging(); app.UseMiddleware<ApiLogMiddleware>(); First we need to setup UseSerilogRequestLogging and second configure ApiLog middleware. Outcoming API calls Also, if you are calling services you need to define an enrich handler when you define service in startup. This are only for external services, our microservices has is own logs methods. services.AddHttpClient<CoreService>(c => { c.BaseAddress = new Uri(externalserviceURL); }).AddHttpMessageHandler<ServiceHandler>(); // Enrich Log when calling service For each external call ServiceHandler.SendAsync is call to add event information in out logs. Configuration To allow Logs working you need to setup in initialitation flow. Code Depends if you use NET 5 or greater. NET 5 Code for NET 5 configuration on program.cs public static void Main(string[] args) { ConfigureLogging(); CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) => Host.CreateDefaultBuilder(args) .ConfigureLogging(logging => { logging.ClearProviders(); logging.AddConsole(); logging.AddDebug(); //Esto hace que se vea en vs code consola de depuraci\u00f3n }) .ConfigureWebHostDefaults(webBuilder => webBuilder.UseStartup<Startup>()) .ConfigureAppConfiguration(configuration => { configuration.AddJsonFile(\"appsettings.json\", optional: false, reloadOnChange: true); configuration.AddEnvironmentVariables(); }) .UseSerilog(); private static void ConfigureLogging() { // Get Application version to Log var productVersion = \"\"; var assembly = Assembly.GetExecutingAssembly(); var assemblyVersion = assembly.GetName().Version; FileVersionInfo fvi = FileVersionInfo.GetVersionInfo(assembly.Location); productVersion = fvi.ProductVersion ?? \"product version not found\"; var environment = Environment.GetEnvironmentVariable(\"ASPNETCORE_ENVIRONMENT\"); var configuration = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\", optional: false, reloadOnChange: true) .AddEnvironmentVariables() .Build(); Log.Logger = new LoggerConfiguration() .Enrich.FromLogContext() .Enrich.WithExceptionDetails(new DestructuringOptionsBuilder() .WithDefaultDestructurers() .WithDestructurers(new[] { new DbUpdateExceptionDestructurer() }) ) .Enrich.WithMachineName() .WriteTo.Debug() .WriteTo.Console() .Enrich.WithProperty(\"Environment\", environment) .Enrich.WithProperty(\"Version\", productVersion) .ReadFrom.Configuration(configuration) .CreateLogger(); } Code for Startup // This allows to enrich without middleware but it does not have response data // app.UseSerilogRequestLogging(opts => opts.EnrichDiagnosticContext = LogHelper.EnrichFromRequest); app.UseSerilogRequestLogging(); app.UseMiddleware<ApiLogMiddleware>(); app.UseAuthentication(); Change configuration from environment variable If you want to change some configuration set in appsetting.json from environment you could set a variable: \"Serilog\": \"{\\\"MinimumLevel\\\": {\\\"Override\\\": {\\\"Serilog.AspNetCore\\\": \\\"Information\\\"}}\", or other option \"Serilog__MinimumLevel__Override__Serilog.AspNetCore\": \"Information\",","title":"Logs"},{"location":"logs/#implementing-backend-logs-in-c","text":"","title":"Implementing backend logs in c"},{"location":"logs/#framework","text":"We use serilog as default framework for our microservices. The package needed are: Serilog.AspNetCore Serilog.Enrichers.Environment Serilog.Exceptions Serilog.Exceptions.EntityFrameworkCore Serilog.Settings.Configuration Serilog.Sinks.Debug","title":"Framework"},{"location":"logs/#sql-server-logs","text":"For use on SQL Server you need to add this package: Serilog.Sinks.MSSqlServer You can create a table for each microservice or define only one table and record all logs.","title":"SQL Server Logs"},{"location":"logs/#postgresql-logs","text":"For use on PostgreSQL you need to add this packages: Serilog.Sinks.PostgreSQL Serilog.Sinks.PostgreSQL.Configuration","title":"PostgreSQL Logs"},{"location":"logs/#configuration","text":"We use configuration on appsettings.json for default or in environment if you need to change some parameter in production to catch a bug. We use some aditionals fields to log information for our microservices: Elapsed: API call time consumed StatusCode: API call status code response Version: Compilation version from csproj RequestMethod: API call method RequestPath: API call endpoint Authorization: JWT sended Host: API call URL Protocol: API call protocol Scheme: API call scheme The following fields are used to know state of call and it are disabled for default throw SaveLogBodies=true appsettings param: QueryString: API call query string with key value information RequestBody: API call request body ResponseBody: API call response body","title":"Configuration"},{"location":"logs/#appsettingsjson","text":"This is an example on how to setup default configuration to log in production. \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Error\", \"Override\": { \"Microsoft\": \"Error\", \"Microsoft.AspNetCore\": \"Error\", \"Serilog.AspNetCore\": \"Error\", \"Microsoft.EntityFrameworkCore\":\"Error\" } } This is only recording errors on all namespaces and setting some overrides nodes that you can change to get more specific information if error happend or you need to test performance. In MinimumLevel Override Each node defines a Namespace and particulary a Log Level to configure. Supouse you need to check time consuming on APIs calls, you can set Serilog.AspNetCore to Information; or maybe you need yo view the query setting Microsoft.EntityFrameworkCore to Information.","title":"Appsettings.json"},{"location":"logs/#sql-configuration","text":"This is the default configuration for SQL Server on each microservice project. \"WriteTo\": [ { \"Name\": \"MSSqlServer\", \"Args\": { \"connectionString\": \"Default\", \"tableName\": \"Logs\", \"autoCreateSqlTable\": true, \"logEventFormatter\": \"Serilog.Formatting.Compact.CompactJsonFormatter, Serilog.Formatting.Compact\", \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"columnOptionsSection\": { \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"addStandardColumns\": [\"LogEvent\"], \"logEvent\": { \"excludeAdditionalProperties\": true, \"excludeStandardColumns\": true }, \"customColumns\": [ { \"ColumnName\": \"Elapsed\", \"DataType\": \"float\" }, { \"ColumnName\": \"StatusCode\", \"DataType\": \"int\" }, { \"ColumnName\": \"Version\", \"DataType\": \"varchar\", \"DataLength\": 50 }, { \"ColumnName\": \"RequestMethod\", \"DataType\": \"varchar\", \"DataLength\": 10 }, { \"ColumnName\": \"RequestPath\", \"DataType\": \"varchar\", \"DataLength\": 300 }, { \"ColumnName\": \"Authorization\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Host\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Protocol\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Scheme\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"QueryString\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"RequestBody\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"ResponseBody\", \"DataType\": \"varchar\" } ] } } } ] The key that can be changed here are: connectionString: it points to database configuration attribute define in ConnectionStrings node. tableName: is the table name where all serillog events are saved. The default is Logs but if you need to change it for debug propouse, you could change this name and save records on other table.","title":"SQL Configuration"},{"location":"logs/#enrich-our-logs","text":"There are differents ways to enrich our event with information that help us to know service status. We can log incoming calls throw a middleware or throw a custom EnrichFromRequest method. Middleware allows to control in depth request call and method is call before executing request so response data is not available yet.","title":"Enrich our logs"},{"location":"logs/#incoming-api-calls","text":"We use a custom middleware ApiLogMiddleware class to enrich our API calls. This allows to get context information and add it to serilog event for recording in database in Invoke method. This middleware is set in our startup process and is important the order. app.UseSerilogRequestLogging(); app.UseMiddleware<ApiLogMiddleware>(); First we need to setup UseSerilogRequestLogging and second configure ApiLog middleware.","title":"Incoming API calls"},{"location":"logs/#outcoming-api-calls","text":"Also, if you are calling services you need to define an enrich handler when you define service in startup. This are only for external services, our microservices has is own logs methods. services.AddHttpClient<CoreService>(c => { c.BaseAddress = new Uri(externalserviceURL); }).AddHttpMessageHandler<ServiceHandler>(); // Enrich Log when calling service For each external call ServiceHandler.SendAsync is call to add event information in out logs.","title":"Outcoming API calls"},{"location":"logs/#configuration_1","text":"To allow Logs working you need to setup in initialitation flow. Code Depends if you use NET 5 or greater.","title":"Configuration"},{"location":"logs/#net-5","text":"Code for NET 5 configuration on program.cs public static void Main(string[] args) { ConfigureLogging(); CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) => Host.CreateDefaultBuilder(args) .ConfigureLogging(logging => { logging.ClearProviders(); logging.AddConsole(); logging.AddDebug(); //Esto hace que se vea en vs code consola de depuraci\u00f3n }) .ConfigureWebHostDefaults(webBuilder => webBuilder.UseStartup<Startup>()) .ConfigureAppConfiguration(configuration => { configuration.AddJsonFile(\"appsettings.json\", optional: false, reloadOnChange: true); configuration.AddEnvironmentVariables(); }) .UseSerilog(); private static void ConfigureLogging() { // Get Application version to Log var productVersion = \"\"; var assembly = Assembly.GetExecutingAssembly(); var assemblyVersion = assembly.GetName().Version; FileVersionInfo fvi = FileVersionInfo.GetVersionInfo(assembly.Location); productVersion = fvi.ProductVersion ?? \"product version not found\"; var environment = Environment.GetEnvironmentVariable(\"ASPNETCORE_ENVIRONMENT\"); var configuration = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\", optional: false, reloadOnChange: true) .AddEnvironmentVariables() .Build(); Log.Logger = new LoggerConfiguration() .Enrich.FromLogContext() .Enrich.WithExceptionDetails(new DestructuringOptionsBuilder() .WithDefaultDestructurers() .WithDestructurers(new[] { new DbUpdateExceptionDestructurer() }) ) .Enrich.WithMachineName() .WriteTo.Debug() .WriteTo.Console() .Enrich.WithProperty(\"Environment\", environment) .Enrich.WithProperty(\"Version\", productVersion) .ReadFrom.Configuration(configuration) .CreateLogger(); } Code for Startup // This allows to enrich without middleware but it does not have response data // app.UseSerilogRequestLogging(opts => opts.EnrichDiagnosticContext = LogHelper.EnrichFromRequest); app.UseSerilogRequestLogging(); app.UseMiddleware<ApiLogMiddleware>(); app.UseAuthentication();","title":"NET 5"},{"location":"logs/#change-configuration-from-environment-variable","text":"If you want to change some configuration set in appsetting.json from environment you could set a variable: \"Serilog\": \"{\\\"MinimumLevel\\\": {\\\"Override\\\": {\\\"Serilog.AspNetCore\\\": \\\"Information\\\"}}\", or other option \"Serilog__MinimumLevel__Override__Serilog.AspNetCore\": \"Information\",","title":"Change configuration from environment variable"},{"location":"microfronts/","text":"Add new micro front copy auth.guard ng new MF setup linter ng add @angular-architects/module-federation ng g m MODULENAME ng g c ventas/pedidos/pedidos-search --skip-tests --inline-style --flat Main.ts en Layout \u00b4\u00b4\u00b4\u00b4 import { loadManifest } from '@angular-architects/module-federation'; loadManifest('/assets/mf.manifest.json') .catch((err) => console.error(err)) .then((_) => import('./bootstrap')) .catch((err) => console.error(err)); \u00b4\u00b4\u00b4\u00b4 Exposes data from microfront webpack.config.js \u00b4\u00b4\u00b4\u00b4 const { shareAll, withModuleFederationPlugin } = require('@angular-architects/module-federation/webpack'); module.exports = withModuleFederationPlugin({ name: 'mfe1', exposes: { // Adjusted line: './Module': './projects/mfe1/src/app/flights/flights.module.ts' }, shared: { ...shareAll({ singleton: true, strictVersion: true, requiredVersion: 'auto' }), }, }); \u00b4\u00b4\u00b4\u00b4 Componentes StandAlone Primero hay que definirlos en el proyecto de angular como: \u00b4\u00b4\u00b4\u00b4 @Component({ selector: 'app-pedidos', standalone: true, <---- ESTO ES IMPORTANTE templateUrl: './pedidos.component.html', styleUrls: ['./pedidos.component.scss'] }) \u00b4\u00b4\u00b4\u00b4 Luego no se definen como declarations en app.module.ts se exponene as\u00ed: \u00b4\u00b4\u00b4\u00b4 exposes: { // \"./routes\": \"./src/app/ventas.routes.ts\", './Module': './src/app/ventas/ventas.module.ts', './Component': './src/app/pedidos/pedidos.component.ts', }, \u00b4\u00b4\u00b4\u00b4 En el shell se declaran en el manifest como: \u00b4\u00b4\u00b4\u00b4 \"pedidos\": { \"remoteEntry\": \"http://localhost:4201/remoteEntry.js\", \"exposedModule\": \"./Component\", \"displayName\": \"pedidos\", \"routePath\": \"pedidos\" } \u00b4\u00b4\u00b4\u00b4 Se cargan como ruta as\u00ed \u00b4\u00b4\u00b4\u00b4 { path: 'pedidos', loadComponent: () => loadRemoteModule({ type: 'module', remoteEntry: 'http://localhost:4201/remoteEntry.js', exposedModule: './Component', }).then((m) => m.PedidosComponent), }, \u00b4\u00b4\u00b4\u00b4 Incluir M\u00f3dulos completos Crear el m\u00f3dulo en el proyecto Agregar los routes como childs en la definci\u00f3n del modulo \u00b4\u00b4\u00b4\u00b4 imports: [ CommonModule, RouterModule.forChild(VENTAS_ROUTES) ] \u00b4\u00b4\u00b4\u00b4 Se exponene as\u00ed en el webpack: \u00b4\u00b4\u00b4\u00b4 exposes: { // \"./routes\": \"./src/app/ventas.routes.ts\", './Module': './src/app/ventas/ventas.module.ts', './Component': './src/app/pedidos/pedidos.component.ts', }, En alg\u00fan proyecto con Angular 14 me tiro que no estaba compilado el m\u00f3dulo, que deb\u00eda incluirlo en tsconfig.app.json como se muestra abajo. \u00b4\u00b4\u00b4\u00b4 \"include\": [\"src/ /*.d.ts\", \" /app/ventas/* / .ts\"] \u00b4\u00b4\u00b4\u00b4 en el shell \u00b4\u00b4\u00b4\u00b4 Se levantan as\u00ed en el manifest: \u00b4\u00b4\u00b4\u00b4 \"admin\": { \"remoteEntry\": \"http://localhost:4201/remoteEntry.js\", \"exposedModule\": \"./Module\", \"displayName\": \"ventasApp\", \"routePath\": \"pedidos\", \"ngModuleName\": \"VentasModule\" }, \u00b4\u00b4\u00b4\u00b4 Se importan las rutas: \u00b4\u00b4\u00b4\u00b4 { path: 'ventas', loadChildren: () => loadRemoteModule({ type: 'manifest', remoteName: 'admin', // name in manifest json exposedModule: './Module', }).then((m) => m.VentasModule), }, \u00b4\u00b4\u00b4\u00b4 Componentes para migrar funcionalidad de Neox Bootstrap (npm i bootstrap) -> Compartido en webpack ngx-toastr (npm i ngx-toastr) -> Compartido en webpack jquery (npm i jquery) -> Compartido en webpack ngx-bootstrap (npm i ngx-bootstrap) -> Compartido en webpack fontawesome icons (npm i @fortawesome/angular-fontawesome, npm i @fortawesome/free-solid-svg-icons) pagination (mpm i ngx-pagination) Popper dropdowns (npm i @popperjs/core) Tabs (npm i) Migrando Crear los componentes en el proyecto Copiar y pegar el TS Pasar los servicios Copiar y pegar el HTML Usar el instructivo de migraci\u00f3n de B4 a B5 que est\u00e1 en esta doc Crear el login-mfe del microproyecto Es un login que se usa para desarrollar y no necesitar abrir el proyecto de layout Copiar la carpeta login-mfe en App Agregar en declarations el LoginMfeComponent Agregar el routing login al LoginMfe { path: 'login', component: LoginMfeComponent, }, Layout Agregar como submodulo el layout y core git submodule add https://github.com/grape-software/microfront Armado de docker para integrar el layout + core + negocio Para el armado del despliegue es necesario crear un docker que contenga el Layout, Core y los microfronts propios del negocio en un solo contenedor. Para ello es importante tener en cuenta cual ser\u00e1 la URL donde estar\u00e1 corriendo el front y las APIs correspondientes. Configuraci\u00f3n del Dockerfile El docker file tiene que compilar los proyectos SPA, incluido los submodulos layout y core. Es importante establecer la variable de entorno donde est\u00e1 el HOST de las urls de las APIs en el entorno donde se vaya a hacer la compilaci\u00f3n. As\u00ed de esta forma se hace un reemplazo en el environment.prod.ts reemplazando {API_HOST}. ENV API_HOST=uni.sandbox.ar Este es un ejemplo de como armar el Dockerfile para desplegar un contenedor de frontend con el layout y todos los microfronts. #Primera Etapa FROM node:16.13.1-alpine3.14 as build-step ENV API_HOST=uni.sandbox.ar #---para CORE RUN mkdir -p /appcore WORKDIR /appcore COPY /microfronts/core/ /appcore RUN npm install COPY . /appcore RUN npm run build #---para LAYOUT RUN mkdir -p /applayout WORKDIR /applayout COPY /microfronts/layout/ /applayout RUN npm install COPY . /applayout RUN npm run build #---para MF Uni RUN mkdir -p /appuni WORKDIR /appuni COPY /universidad/ /appuni RUN npm install COPY . /appuni RUN npm run build #Segunda Etapa FROM nginx:1.17.1-alpine #copio los sites RUN mkdir /usr/share/nginx/html/core RUN mkdir /usr/share/nginx/html/layout RUN mkdir /usr/share/nginx/html/uni COPY --from=build-step /appcore/dist/core/es/ /usr/share/nginx/html/core COPY --from=build-step /applayout/dist/neox/ /usr/share/nginx/html/layout COPY --from=build-step /appuni/dist/universidad/ /usr/share/nginx/html/uni # COPY ./microfronts/core/dist/core/es/ /usr/share/nginx/html/core # COPY ./microfronts/layout/dist/neox/ /usr/share/nginx/html/layout # COPY ./universidad/dist/universidad/ /usr/share/nginx/html/uni #copio config del nginx COPY nginx.conf /etc/nginx # COPY nginx.conf /etc/nginx/conf.d/default.conf EXPOSE 80 Configuraci\u00f3n del nginx Para poder armar la configuraci\u00f3n es necesario notar que el punto de ingreso ser\u00e1 el shell Layout, quien luego levantar\u00e1 de la tabla Microfront de la base de datos la configuraci\u00f3n del resto. events{} http { include /etc/nginx/mime.types; server { listen 80; server_name uni.sandbox.ar; # <-- URL donde queda el destino en prod root /usr/share/nginx/html/; index index.html; location / { root /usr/share/nginx/html/layout; # <-- Proyecto Layout try_files $uri $uri/ index.html; } # Microfronts tiene que estar configurado el publicPath del webpack.config de cada microfront. Ej /core/ o /uni/ location ^~/core { root /usr/share/nginx/html/core; } location ^~/uni { root /usr/share/nginx/html/uni; } } } Configuraci\u00f3n de los microfronts webpack.config output: { uniqueName: 'universidad', publicPath: '/uni/', <-- ESTO ES IMPORTANTE TIENE QUE ESTAR EN EL NGINX QUE LO SIRVA COMO CONTENIDO ESTATICO },","title":"Microfronts"},{"location":"microfronts/#add-new-micro-front","text":"copy auth.guard ng new MF setup linter ng add @angular-architects/module-federation ng g m MODULENAME ng g c ventas/pedidos/pedidos-search --skip-tests --inline-style --flat","title":"Add new micro front"},{"location":"microfronts/#maints-en-layout","text":"\u00b4\u00b4\u00b4\u00b4 import { loadManifest } from '@angular-architects/module-federation'; loadManifest('/assets/mf.manifest.json') .catch((err) => console.error(err)) .then((_) => import('./bootstrap')) .catch((err) => console.error(err)); \u00b4\u00b4\u00b4\u00b4","title":"Main.ts en Layout"},{"location":"microfronts/#exposes-data-from-microfront-webpackconfigjs","text":"\u00b4\u00b4\u00b4\u00b4 const { shareAll, withModuleFederationPlugin } = require('@angular-architects/module-federation/webpack'); module.exports = withModuleFederationPlugin({ name: 'mfe1', exposes: { // Adjusted line: './Module': './projects/mfe1/src/app/flights/flights.module.ts' }, shared: { ...shareAll({ singleton: true, strictVersion: true, requiredVersion: 'auto' }), }, }); \u00b4\u00b4\u00b4\u00b4","title":"Exposes data from microfront webpack.config.js"},{"location":"microfronts/#componentes-standalone","text":"Primero hay que definirlos en el proyecto de angular como: \u00b4\u00b4\u00b4\u00b4 @Component({ selector: 'app-pedidos', standalone: true, <---- ESTO ES IMPORTANTE templateUrl: './pedidos.component.html', styleUrls: ['./pedidos.component.scss'] }) \u00b4\u00b4\u00b4\u00b4 Luego no se definen como declarations en app.module.ts se exponene as\u00ed: \u00b4\u00b4\u00b4\u00b4 exposes: { // \"./routes\": \"./src/app/ventas.routes.ts\", './Module': './src/app/ventas/ventas.module.ts', './Component': './src/app/pedidos/pedidos.component.ts', }, \u00b4\u00b4\u00b4\u00b4 En el shell se declaran en el manifest como: \u00b4\u00b4\u00b4\u00b4 \"pedidos\": { \"remoteEntry\": \"http://localhost:4201/remoteEntry.js\", \"exposedModule\": \"./Component\", \"displayName\": \"pedidos\", \"routePath\": \"pedidos\" } \u00b4\u00b4\u00b4\u00b4 Se cargan como ruta as\u00ed \u00b4\u00b4\u00b4\u00b4 { path: 'pedidos', loadComponent: () => loadRemoteModule({ type: 'module', remoteEntry: 'http://localhost:4201/remoteEntry.js', exposedModule: './Component', }).then((m) => m.PedidosComponent), }, \u00b4\u00b4\u00b4\u00b4","title":"Componentes StandAlone"},{"location":"microfronts/#incluir-modulos-completos","text":"Crear el m\u00f3dulo en el proyecto Agregar los routes como childs en la definci\u00f3n del modulo \u00b4\u00b4\u00b4\u00b4 imports: [ CommonModule, RouterModule.forChild(VENTAS_ROUTES) ] \u00b4\u00b4\u00b4\u00b4 Se exponene as\u00ed en el webpack: \u00b4\u00b4\u00b4\u00b4 exposes: { // \"./routes\": \"./src/app/ventas.routes.ts\", './Module': './src/app/ventas/ventas.module.ts', './Component': './src/app/pedidos/pedidos.component.ts', }, En alg\u00fan proyecto con Angular 14 me tiro que no estaba compilado el m\u00f3dulo, que deb\u00eda incluirlo en tsconfig.app.json como se muestra abajo. \u00b4\u00b4\u00b4\u00b4 \"include\": [\"src/ /*.d.ts\", \" /app/ventas/* / .ts\"] \u00b4\u00b4\u00b4\u00b4","title":"Incluir M\u00f3dulos completos"},{"location":"microfronts/#en-el-shell","text":"\u00b4\u00b4\u00b4\u00b4 Se levantan as\u00ed en el manifest: \u00b4\u00b4\u00b4\u00b4 \"admin\": { \"remoteEntry\": \"http://localhost:4201/remoteEntry.js\", \"exposedModule\": \"./Module\", \"displayName\": \"ventasApp\", \"routePath\": \"pedidos\", \"ngModuleName\": \"VentasModule\" }, \u00b4\u00b4\u00b4\u00b4 Se importan las rutas: \u00b4\u00b4\u00b4\u00b4 { path: 'ventas', loadChildren: () => loadRemoteModule({ type: 'manifest', remoteName: 'admin', // name in manifest json exposedModule: './Module', }).then((m) => m.VentasModule), }, \u00b4\u00b4\u00b4\u00b4","title":"en el shell"},{"location":"microfronts/#componentes-para-migrar-funcionalidad-de-neox","text":"Bootstrap (npm i bootstrap) -> Compartido en webpack ngx-toastr (npm i ngx-toastr) -> Compartido en webpack jquery (npm i jquery) -> Compartido en webpack ngx-bootstrap (npm i ngx-bootstrap) -> Compartido en webpack fontawesome icons (npm i @fortawesome/angular-fontawesome, npm i @fortawesome/free-solid-svg-icons) pagination (mpm i ngx-pagination) Popper dropdowns (npm i @popperjs/core) Tabs (npm i)","title":"Componentes para migrar funcionalidad de Neox"},{"location":"microfronts/#migrando","text":"Crear los componentes en el proyecto Copiar y pegar el TS Pasar los servicios Copiar y pegar el HTML Usar el instructivo de migraci\u00f3n de B4 a B5 que est\u00e1 en esta doc","title":"Migrando"},{"location":"microfronts/#crear-el-login-mfe-del-microproyecto","text":"Es un login que se usa para desarrollar y no necesitar abrir el proyecto de layout Copiar la carpeta login-mfe en App Agregar en declarations el LoginMfeComponent Agregar el routing login al LoginMfe { path: 'login', component: LoginMfeComponent, },","title":"Crear el login-mfe del microproyecto"},{"location":"microfronts/#layout","text":"Agregar como submodulo el layout y core git submodule add https://github.com/grape-software/microfront","title":"Layout"},{"location":"microfronts/#armado-de-docker-para-integrar-el-layout-core-negocio","text":"Para el armado del despliegue es necesario crear un docker que contenga el Layout, Core y los microfronts propios del negocio en un solo contenedor. Para ello es importante tener en cuenta cual ser\u00e1 la URL donde estar\u00e1 corriendo el front y las APIs correspondientes.","title":"Armado de docker para integrar el layout + core + negocio"},{"location":"microfronts/#configuracion-del-dockerfile","text":"El docker file tiene que compilar los proyectos SPA, incluido los submodulos layout y core. Es importante establecer la variable de entorno donde est\u00e1 el HOST de las urls de las APIs en el entorno donde se vaya a hacer la compilaci\u00f3n. As\u00ed de esta forma se hace un reemplazo en el environment.prod.ts reemplazando {API_HOST}. ENV API_HOST=uni.sandbox.ar Este es un ejemplo de como armar el Dockerfile para desplegar un contenedor de frontend con el layout y todos los microfronts. #Primera Etapa FROM node:16.13.1-alpine3.14 as build-step ENV API_HOST=uni.sandbox.ar #---para CORE RUN mkdir -p /appcore WORKDIR /appcore COPY /microfronts/core/ /appcore RUN npm install COPY . /appcore RUN npm run build #---para LAYOUT RUN mkdir -p /applayout WORKDIR /applayout COPY /microfronts/layout/ /applayout RUN npm install COPY . /applayout RUN npm run build #---para MF Uni RUN mkdir -p /appuni WORKDIR /appuni COPY /universidad/ /appuni RUN npm install COPY . /appuni RUN npm run build #Segunda Etapa FROM nginx:1.17.1-alpine #copio los sites RUN mkdir /usr/share/nginx/html/core RUN mkdir /usr/share/nginx/html/layout RUN mkdir /usr/share/nginx/html/uni COPY --from=build-step /appcore/dist/core/es/ /usr/share/nginx/html/core COPY --from=build-step /applayout/dist/neox/ /usr/share/nginx/html/layout COPY --from=build-step /appuni/dist/universidad/ /usr/share/nginx/html/uni # COPY ./microfronts/core/dist/core/es/ /usr/share/nginx/html/core # COPY ./microfronts/layout/dist/neox/ /usr/share/nginx/html/layout # COPY ./universidad/dist/universidad/ /usr/share/nginx/html/uni #copio config del nginx COPY nginx.conf /etc/nginx # COPY nginx.conf /etc/nginx/conf.d/default.conf EXPOSE 80","title":"Configuraci\u00f3n del Dockerfile"},{"location":"microfronts/#configuracion-del-nginx","text":"Para poder armar la configuraci\u00f3n es necesario notar que el punto de ingreso ser\u00e1 el shell Layout, quien luego levantar\u00e1 de la tabla Microfront de la base de datos la configuraci\u00f3n del resto. events{} http { include /etc/nginx/mime.types; server { listen 80; server_name uni.sandbox.ar; # <-- URL donde queda el destino en prod root /usr/share/nginx/html/; index index.html; location / { root /usr/share/nginx/html/layout; # <-- Proyecto Layout try_files $uri $uri/ index.html; } # Microfronts tiene que estar configurado el publicPath del webpack.config de cada microfront. Ej /core/ o /uni/ location ^~/core { root /usr/share/nginx/html/core; } location ^~/uni { root /usr/share/nginx/html/uni; } } }","title":"Configuraci\u00f3n del nginx"},{"location":"microfronts/#configuracion-de-los-microfronts-webpackconfig","text":"output: { uniqueName: 'universidad', publicPath: '/uni/', <-- ESTO ES IMPORTANTE TIENE QUE ESTAR EN EL NGINX QUE LO SIRVA COMO CONTENIDO ESTATICO },","title":"Configuraci\u00f3n de los microfronts webpack.config"},{"location":"microservices/","text":"Microservices Grape Docs Web Api solution dotnet new sln --name MySolution dotnet new classlib --output lib dotnet sln add lib dotnet new webapi --output services dotnet sln add services Adding Core First create NuGet.Config file in root solution folder and add content below, changing Username and ClearTextPassword (should be PAT from Github account with permissions on below repository indicated) <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <packageSources> <clear /> <add key=\"github\" value=\"https://nuget.pkg.github.com/macro-i/index.json\" /> <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" protocolVersion=\"3\" /> </packageSources> <packageSourceCredentials> <github> <add key=\"Username\" value=\"XXXX\" /> <add key=\"ClearTextPassword\" value=\"XXXXX\" /> </github> </packageSourceCredentials> </configuration> Mostly a microservice use User and other business objects to build is own logic. This should be done adding package Grape.Core from private repo https://github.com/grape-software/core/packages with the follow command: dotnet add lib package Grape.Core --version X.X.X Web Api Packages En el directorio del proyecto de APIs dotnet add package Microsoft.EntityFrameworkCore.SqlServer dotnet add package Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite dotnet add package Microsoft.AspNetCore.Mvc.NewtonsoftJson dotnet add package Microsoft.AspNetCore.Authentication.JwtBearer dotnet add package Newtonsoft.Json dotnet add package Serilog.AspNetCore dotnet add package Serilog.Enrichers.Environment dotnet add package Serilog.Exceptions dotnet add package Serilog.Exceptions.EntityFrameworkCore dotnet add package Serilog.Settings.Configuration dotnet add package Serilog.Sinks.Debug dotnet add package Serilog.Sinks.MSSqlServer dotnet add package Swashbuckle.AspNetCore dotnet add package System.IdentityModel.Tokens.Jwt dotnet add package System.Linq.Dynamic.Core C\u00f3digo del archivo de proyecto <PropertyGroup> <TargetFramework>net7.0</TargetFramework> <Nullable>enable</Nullable> <ImplicitUsings>enable</ImplicitUsings> <RootNamespace></RootNamespace> <LangVersion>latest</LangVersion> <GenerateDocumentationFile>true</GenerateDocumentationFile> <NoWarn>$(NoWarn);1591;1572;1573;</NoWarn> <Nullable>enable</Nullable> <VersionPrefix>0.0.0</VersionPrefix> <VersionSuffix>$([System.DateTime]::UtcNow.ToString(`yyyyMMdd-HHmm`))</VersionSuffix> </PropertyGroup> <ItemGroup> <ProjectReference Include=\"..\\lib\\lib.csproj\" /> </ItemGroup> C\u00f3digo del Program.cs Con SQL Server este es el c\u00f3digo using System.Diagnostics; using System.Globalization; using System.Reflection; using System.Text; using Microsoft.AspNetCore.Authentication.JwtBearer; // using Microsoft.AspNetCore.Authentication.JwtBearer; using Microsoft.EntityFrameworkCore; using Microsoft.IdentityModel.Tokens; using Microsoft.OpenApi.Models; using Newtonsoft.Json; using Serilog; using Serilog.Exceptions; using Serilog.Exceptions.Core; using Serilog.Exceptions.EntityFrameworkCore.Destructurers; using Swashbuckle.AspNetCore.SwaggerUI; var builder = WebApplication.CreateBuilder(args); // Get Application version to Log var productVersion = \"\"; var assembly = Assembly.GetExecutingAssembly(); var assemblyVersion = assembly.GetName().Version; FileVersionInfo fvi = FileVersionInfo.GetVersionInfo(assembly.Location); productVersion = fvi.ProductVersion ?? \"product version not found\"; // For comments on OpenApi Swagger var basePath = AppContext.BaseDirectory; //Microsoft.DotNet.PlatformAbstractions.ApplicationEnvironment.ApplicationBasePath; var fileName = typeof(Program).GetTypeInfo().Assembly.GetName().Name + \".xml\"; var xmlCommentsPath = Path.Combine(basePath, fileName); ; // Configuration builder.Configuration.AddEnvironmentVariables(); // Add environment variables // Write Log with Serilog builder.Host.UseSerilog((ctx, lc) => { lc.Enrich.FromLogContext(); lc.Enrich.WithExceptionDetails(new DestructuringOptionsBuilder() .WithDefaultDestructurers() .WithDestructurers(new[] { new DbUpdateExceptionDestructurer() }) ); lc.Enrich.WithMachineName(); lc.WriteTo.Debug(); lc.WriteTo.Console(); lc.Enrich.WithProperty(\"Version\", productVersion); lc.ReadFrom.Configuration(ctx.Configuration); }); builder.Services.AddControllers().AddNewtonsoftJson(x => { x.SerializerSettings.ReferenceLoopHandling = ReferenceLoopHandling.Ignore; }); // Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle builder.Services.AddEndpointsApiExplorer(); builder.Services.AddSwaggerGen(c => { c.SwaggerDoc(\"v1\", new OpenApiInfo { Version = \"v1\", Title = \"Microservicio APIs\", Description = \"REST APIs del Microservicio\", TermsOfService = new Uri(\"http://www.DOMINIO.com.ar/\"), Contact = new OpenApiContact { Name = \"Admin\", Email = \"mail@DOMINIO.com.ar\", }, License = new OpenApiLicense { Name = \"Use under LICX\", Url = new Uri(\"http://www.DOMINIO.com.ar/\"), } }); if (!string.IsNullOrWhiteSpace(xmlCommentsPath)) c.IncludeXmlComments(xmlCommentsPath); }); // string[] hostAuthorized = { \"http://localhost:4200\", \"http://localhost:4205\", \"http://localhost:8089\" }; builder.Services.AddCors(options => { options.AddPolicy(\"CorsPolicy\", builder => builder // Add urls to allows connection to signalr and rest of services // .WithOrigins(hostAuthorized) .SetIsOriginAllowed(origin => true) // allow any origin .AllowAnyMethod() .AllowAnyHeader() .AllowCredentials()); }); builder.Services.AddDbContextPool<AppDBContext>(c => { //c.UseSqlite(sqliteString); c.UseSqlServer(builder.Configuration.GetConnectionString(\"Default\"), x => x.UseNetTopologySuite()); #if DEBUG c.EnableSensitiveDataLogging(); #endif }, poolSize: 600); var key = Encoding.ASCII.GetBytes(\"DefaultJWT\"); var dbBuilder = new DbContextOptionsBuilder<AppDBContext>(); dbBuilder // .EnableSensitiveDataLogging() // .UseSqlite(sqliteString); .UseSqlServer(builder.Configuration.GetConnectionString(\"Default\"), x => x.UseNetTopologySuite()); // .UseSnakeCaseNamingConvention() // .UseNpgsql(Configuration.GetConnectionString(\"Default\")); // WRN: Si la base no esta esto tira error using (AppDBContext db = new AppDBContext(dbBuilder.Options)) { // db.Database.EnsureCreated(); // remove in production // JWT Secret key = Encoding.ASCII.GetBytes(db.SystemsParameters.FirstOrDefault(z => z.Code == \"JwtSecret\")?.Value ?? \"Core2020-With-High-Security\"); } builder.Services.AddAuthentication(x => { x.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme; x.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme; }) .AddJwtBearer(x => { x.RequireHttpsMetadata = false; x.SaveToken = true; x.TokenValidationParameters = new TokenValidationParameters { ValidateIssuerSigningKey = true, IssuerSigningKey = new SymmetricSecurityKey(key), ValidateIssuer = false, ValidateAudience = false }; }); builder.Services.AddHttpContextAccessor(); // builder.Services.AddHttpClient<Services.Google.Maps>(c => // { // // Primero busca en la base si est\u00e1 configurada la URL del host y sino en archivo de configuracion // c.BaseAddress = new Uri(\"https://maps.googleapis.com\"); // }); //.AddHttpMessageHandler<ServiceHandler>(); // Enrich Log when calling service; var app = builder.Build(); // sets microservice default culture var cultureInfo = new CultureInfo(\"es-AR\"); CultureInfo.DefaultThreadCurrentCulture = cultureInfo; CultureInfo.DefaultThreadCurrentUICulture = cultureInfo; // Configure the HTTP request pipeline. if (app.Environment.IsDevelopment()) { app.UseSwagger(c => c.RouteTemplate = \"docs/{documentName}/swagger.json\"); app.UseSwaggerUI(c => { c.RoutePrefix = \"docs\"; c.SwaggerEndpoint(\"v1/swagger.json\", \"Documentaci\u00f3n APIs\"); c.DocExpansion(DocExpansion.None); }); } app.UseHttpsRedirection(); app.UseCors(\"CorsPolicy\"); // This allows to enrich without middleware but it does not have response data // app.UseSerilogRequestLogging(opts => opts.EnrichDiagnosticContext = LogHelper.EnrichFromRequest); //app.UseSerilogRequestLogging(); //app.UseMiddleware<ApiLogMiddleware>(); app.UseAuthentication(); app.UseAuthorization(); app.MapControllers(); app.Run(); Agregado de AppDBContext.cs using Microsoft.EntityFrameworkCore; public partial class AppDBContext : DbContext { public AppDBContext(DbContextOptions options) : base(options) { } protected override void OnModelCreating(ModelBuilder modelBuilder) { base.OnModelCreating(modelBuilder); // Evitar delete en cascada foreach (var relationship in modelBuilder.Model.GetEntityTypes().SelectMany(e => e.GetForeignKeys())) { relationship.DeleteBehavior = DeleteBehavior.Restrict; } // #region Auth // modelBuilder.Entity<User>(entity => // { // entity.HasIndex(e => e.Identifier).IsUnique(); // entity.HasIndex(e => e.ExternalID); // }); // #endregion // #region Enums // modelBuilder // .Entity<ConvenioCobro>() // .Property(e => e.FormaPago) // .HasConversion<string>(); // #endregion #region Views // modelBuilder.Entity<EstadoFinancieroResult>(e => e.ToView(\"EstadoFinanciero\").HasNoKey()); // modelBuilder.Entity<CuentaCorrienteResult>(e => e.ToView(\"CuentaCorriente\").HasNoKey()); #endregion } } appsettings.json { \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Debug\", \"Override\": { \"Microsoft\": \"Information\", \"Microsoft.AspNetCore\": \"Information\", // To log all calls set this as Information \"Serilog.AspNetCore\": \"Information\", \"Microsoft.EntityFrameworkCore\": \"Information\" } }, \"WriteTo\": [ { \"Name\": \"MSSqlServer\", \"Args\": { \"connectionString\": \"Default\", \"tableName\": \"Logs\", \"autoCreateSqlTable\": true, \"logEventFormatter\": \"Serilog.Formatting.Compact.CompactJsonFormatter, Serilog.Formatting.Compact\", \"removeStandardColumns\": [\"Properties\"], \"columnOptionsSection\": { \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"addStandardColumns\": [\"LogEvent\"], \"logEvent\": { \"excludeAdditionalProperties\": true, \"excludeStandardColumns\": true }, \"customColumns\": [ { \"ColumnName\": \"Elapsed\", \"DataType\": \"float\" }, { \"ColumnName\": \"StatusCode\", \"DataType\": \"int\" }, { \"ColumnName\": \"Version\", \"DataType\": \"varchar\", \"DataLength\": 50 }, { \"ColumnName\": \"RequestMethod\", \"DataType\": \"varchar\", \"DataLength\": 10 }, { \"ColumnName\": \"RequestPath\", \"DataType\": \"varchar\", \"DataLength\": 300 }, { \"ColumnName\": \"Authorization\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Host\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Protocol\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Scheme\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"QueryString\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"RequestBody\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"ResponseBody\", \"DataType\": \"varchar\" } ] } } } ] }, // Para loguear los bodies response y request \"SaveLogBodies\": \"true\", \"AllowedHosts\": \"*\", \"ConnectionStrings\": { \"Default\": \"Server=(local);Initial Catalog=XXXX;Persist Security Info=False;User ID=XXXX;Password=XXXX;MultipleActiveResultSets=True;Connection Timeout=30;TrustServerCertificate=True;\" // \"Default\": \"Server=tcp:sql-docean.grape.com.ar,14330;Initial Catalog=XXXX;Persist Security Info=False;User ID=XXXX;Password=XXXXX;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;\" } }","title":"Microservices"},{"location":"microservices/#microservices-grape-docs","text":"","title":"Microservices Grape Docs"},{"location":"microservices/#web-api-solution","text":"dotnet new sln --name MySolution dotnet new classlib --output lib dotnet sln add lib dotnet new webapi --output services dotnet sln add services","title":"Web Api solution"},{"location":"microservices/#adding-core","text":"First create NuGet.Config file in root solution folder and add content below, changing Username and ClearTextPassword (should be PAT from Github account with permissions on below repository indicated) <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <packageSources> <clear /> <add key=\"github\" value=\"https://nuget.pkg.github.com/macro-i/index.json\" /> <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" protocolVersion=\"3\" /> </packageSources> <packageSourceCredentials> <github> <add key=\"Username\" value=\"XXXX\" /> <add key=\"ClearTextPassword\" value=\"XXXXX\" /> </github> </packageSourceCredentials> </configuration> Mostly a microservice use User and other business objects to build is own logic. This should be done adding package Grape.Core from private repo https://github.com/grape-software/core/packages with the follow command: dotnet add lib package Grape.Core --version X.X.X","title":"Adding Core"},{"location":"microservices/#web-api-packages","text":"En el directorio del proyecto de APIs dotnet add package Microsoft.EntityFrameworkCore.SqlServer dotnet add package Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite dotnet add package Microsoft.AspNetCore.Mvc.NewtonsoftJson dotnet add package Microsoft.AspNetCore.Authentication.JwtBearer dotnet add package Newtonsoft.Json dotnet add package Serilog.AspNetCore dotnet add package Serilog.Enrichers.Environment dotnet add package Serilog.Exceptions dotnet add package Serilog.Exceptions.EntityFrameworkCore dotnet add package Serilog.Settings.Configuration dotnet add package Serilog.Sinks.Debug dotnet add package Serilog.Sinks.MSSqlServer dotnet add package Swashbuckle.AspNetCore dotnet add package System.IdentityModel.Tokens.Jwt dotnet add package System.Linq.Dynamic.Core C\u00f3digo del archivo de proyecto <PropertyGroup> <TargetFramework>net7.0</TargetFramework> <Nullable>enable</Nullable> <ImplicitUsings>enable</ImplicitUsings> <RootNamespace></RootNamespace> <LangVersion>latest</LangVersion> <GenerateDocumentationFile>true</GenerateDocumentationFile> <NoWarn>$(NoWarn);1591;1572;1573;</NoWarn> <Nullable>enable</Nullable> <VersionPrefix>0.0.0</VersionPrefix> <VersionSuffix>$([System.DateTime]::UtcNow.ToString(`yyyyMMdd-HHmm`))</VersionSuffix> </PropertyGroup> <ItemGroup> <ProjectReference Include=\"..\\lib\\lib.csproj\" /> </ItemGroup>","title":"Web Api Packages"},{"location":"microservices/#codigo-del-programcs","text":"Con SQL Server este es el c\u00f3digo using System.Diagnostics; using System.Globalization; using System.Reflection; using System.Text; using Microsoft.AspNetCore.Authentication.JwtBearer; // using Microsoft.AspNetCore.Authentication.JwtBearer; using Microsoft.EntityFrameworkCore; using Microsoft.IdentityModel.Tokens; using Microsoft.OpenApi.Models; using Newtonsoft.Json; using Serilog; using Serilog.Exceptions; using Serilog.Exceptions.Core; using Serilog.Exceptions.EntityFrameworkCore.Destructurers; using Swashbuckle.AspNetCore.SwaggerUI; var builder = WebApplication.CreateBuilder(args); // Get Application version to Log var productVersion = \"\"; var assembly = Assembly.GetExecutingAssembly(); var assemblyVersion = assembly.GetName().Version; FileVersionInfo fvi = FileVersionInfo.GetVersionInfo(assembly.Location); productVersion = fvi.ProductVersion ?? \"product version not found\"; // For comments on OpenApi Swagger var basePath = AppContext.BaseDirectory; //Microsoft.DotNet.PlatformAbstractions.ApplicationEnvironment.ApplicationBasePath; var fileName = typeof(Program).GetTypeInfo().Assembly.GetName().Name + \".xml\"; var xmlCommentsPath = Path.Combine(basePath, fileName); ; // Configuration builder.Configuration.AddEnvironmentVariables(); // Add environment variables // Write Log with Serilog builder.Host.UseSerilog((ctx, lc) => { lc.Enrich.FromLogContext(); lc.Enrich.WithExceptionDetails(new DestructuringOptionsBuilder() .WithDefaultDestructurers() .WithDestructurers(new[] { new DbUpdateExceptionDestructurer() }) ); lc.Enrich.WithMachineName(); lc.WriteTo.Debug(); lc.WriteTo.Console(); lc.Enrich.WithProperty(\"Version\", productVersion); lc.ReadFrom.Configuration(ctx.Configuration); }); builder.Services.AddControllers().AddNewtonsoftJson(x => { x.SerializerSettings.ReferenceLoopHandling = ReferenceLoopHandling.Ignore; }); // Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle builder.Services.AddEndpointsApiExplorer(); builder.Services.AddSwaggerGen(c => { c.SwaggerDoc(\"v1\", new OpenApiInfo { Version = \"v1\", Title = \"Microservicio APIs\", Description = \"REST APIs del Microservicio\", TermsOfService = new Uri(\"http://www.DOMINIO.com.ar/\"), Contact = new OpenApiContact { Name = \"Admin\", Email = \"mail@DOMINIO.com.ar\", }, License = new OpenApiLicense { Name = \"Use under LICX\", Url = new Uri(\"http://www.DOMINIO.com.ar/\"), } }); if (!string.IsNullOrWhiteSpace(xmlCommentsPath)) c.IncludeXmlComments(xmlCommentsPath); }); // string[] hostAuthorized = { \"http://localhost:4200\", \"http://localhost:4205\", \"http://localhost:8089\" }; builder.Services.AddCors(options => { options.AddPolicy(\"CorsPolicy\", builder => builder // Add urls to allows connection to signalr and rest of services // .WithOrigins(hostAuthorized) .SetIsOriginAllowed(origin => true) // allow any origin .AllowAnyMethod() .AllowAnyHeader() .AllowCredentials()); }); builder.Services.AddDbContextPool<AppDBContext>(c => { //c.UseSqlite(sqliteString); c.UseSqlServer(builder.Configuration.GetConnectionString(\"Default\"), x => x.UseNetTopologySuite()); #if DEBUG c.EnableSensitiveDataLogging(); #endif }, poolSize: 600); var key = Encoding.ASCII.GetBytes(\"DefaultJWT\"); var dbBuilder = new DbContextOptionsBuilder<AppDBContext>(); dbBuilder // .EnableSensitiveDataLogging() // .UseSqlite(sqliteString); .UseSqlServer(builder.Configuration.GetConnectionString(\"Default\"), x => x.UseNetTopologySuite()); // .UseSnakeCaseNamingConvention() // .UseNpgsql(Configuration.GetConnectionString(\"Default\")); // WRN: Si la base no esta esto tira error using (AppDBContext db = new AppDBContext(dbBuilder.Options)) { // db.Database.EnsureCreated(); // remove in production // JWT Secret key = Encoding.ASCII.GetBytes(db.SystemsParameters.FirstOrDefault(z => z.Code == \"JwtSecret\")?.Value ?? \"Core2020-With-High-Security\"); } builder.Services.AddAuthentication(x => { x.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme; x.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme; }) .AddJwtBearer(x => { x.RequireHttpsMetadata = false; x.SaveToken = true; x.TokenValidationParameters = new TokenValidationParameters { ValidateIssuerSigningKey = true, IssuerSigningKey = new SymmetricSecurityKey(key), ValidateIssuer = false, ValidateAudience = false }; }); builder.Services.AddHttpContextAccessor(); // builder.Services.AddHttpClient<Services.Google.Maps>(c => // { // // Primero busca en la base si est\u00e1 configurada la URL del host y sino en archivo de configuracion // c.BaseAddress = new Uri(\"https://maps.googleapis.com\"); // }); //.AddHttpMessageHandler<ServiceHandler>(); // Enrich Log when calling service; var app = builder.Build(); // sets microservice default culture var cultureInfo = new CultureInfo(\"es-AR\"); CultureInfo.DefaultThreadCurrentCulture = cultureInfo; CultureInfo.DefaultThreadCurrentUICulture = cultureInfo; // Configure the HTTP request pipeline. if (app.Environment.IsDevelopment()) { app.UseSwagger(c => c.RouteTemplate = \"docs/{documentName}/swagger.json\"); app.UseSwaggerUI(c => { c.RoutePrefix = \"docs\"; c.SwaggerEndpoint(\"v1/swagger.json\", \"Documentaci\u00f3n APIs\"); c.DocExpansion(DocExpansion.None); }); } app.UseHttpsRedirection(); app.UseCors(\"CorsPolicy\"); // This allows to enrich without middleware but it does not have response data // app.UseSerilogRequestLogging(opts => opts.EnrichDiagnosticContext = LogHelper.EnrichFromRequest); //app.UseSerilogRequestLogging(); //app.UseMiddleware<ApiLogMiddleware>(); app.UseAuthentication(); app.UseAuthorization(); app.MapControllers(); app.Run();","title":"C\u00f3digo del Program.cs"},{"location":"microservices/#agregado-de-appdbcontextcs","text":"using Microsoft.EntityFrameworkCore; public partial class AppDBContext : DbContext { public AppDBContext(DbContextOptions options) : base(options) { } protected override void OnModelCreating(ModelBuilder modelBuilder) { base.OnModelCreating(modelBuilder); // Evitar delete en cascada foreach (var relationship in modelBuilder.Model.GetEntityTypes().SelectMany(e => e.GetForeignKeys())) { relationship.DeleteBehavior = DeleteBehavior.Restrict; } // #region Auth // modelBuilder.Entity<User>(entity => // { // entity.HasIndex(e => e.Identifier).IsUnique(); // entity.HasIndex(e => e.ExternalID); // }); // #endregion // #region Enums // modelBuilder // .Entity<ConvenioCobro>() // .Property(e => e.FormaPago) // .HasConversion<string>(); // #endregion #region Views // modelBuilder.Entity<EstadoFinancieroResult>(e => e.ToView(\"EstadoFinanciero\").HasNoKey()); // modelBuilder.Entity<CuentaCorrienteResult>(e => e.ToView(\"CuentaCorriente\").HasNoKey()); #endregion } }","title":"Agregado de AppDBContext.cs"},{"location":"microservices/#appsettingsjson","text":"{ \"Serilog\": { \"MinimumLevel\": { \"Default\": \"Debug\", \"Override\": { \"Microsoft\": \"Information\", \"Microsoft.AspNetCore\": \"Information\", // To log all calls set this as Information \"Serilog.AspNetCore\": \"Information\", \"Microsoft.EntityFrameworkCore\": \"Information\" } }, \"WriteTo\": [ { \"Name\": \"MSSqlServer\", \"Args\": { \"connectionString\": \"Default\", \"tableName\": \"Logs\", \"autoCreateSqlTable\": true, \"logEventFormatter\": \"Serilog.Formatting.Compact.CompactJsonFormatter, Serilog.Formatting.Compact\", \"removeStandardColumns\": [\"Properties\"], \"columnOptionsSection\": { \"removeStandardColumns\": [\"Properties\", \"MessageTemplate\"], \"addStandardColumns\": [\"LogEvent\"], \"logEvent\": { \"excludeAdditionalProperties\": true, \"excludeStandardColumns\": true }, \"customColumns\": [ { \"ColumnName\": \"Elapsed\", \"DataType\": \"float\" }, { \"ColumnName\": \"StatusCode\", \"DataType\": \"int\" }, { \"ColumnName\": \"Version\", \"DataType\": \"varchar\", \"DataLength\": 50 }, { \"ColumnName\": \"RequestMethod\", \"DataType\": \"varchar\", \"DataLength\": 10 }, { \"ColumnName\": \"RequestPath\", \"DataType\": \"varchar\", \"DataLength\": 300 }, { \"ColumnName\": \"Authorization\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Host\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Protocol\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"Scheme\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"QueryString\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"RequestBody\", \"DataType\": \"varchar\" }, { \"ColumnName\": \"ResponseBody\", \"DataType\": \"varchar\" } ] } } } ] }, // Para loguear los bodies response y request \"SaveLogBodies\": \"true\", \"AllowedHosts\": \"*\", \"ConnectionStrings\": { \"Default\": \"Server=(local);Initial Catalog=XXXX;Persist Security Info=False;User ID=XXXX;Password=XXXX;MultipleActiveResultSets=True;Connection Timeout=30;TrustServerCertificate=True;\" // \"Default\": \"Server=tcp:sql-docean.grape.com.ar,14330;Initial Catalog=XXXX;Persist Security Info=False;User ID=XXXX;Password=XXXXX;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=True;Connection Timeout=30;\" } }","title":"appsettings.json"},{"location":"ms-jobs/","text":"Uso del microservicio Jobs y templates El microservicio Jobs tiene los siguientes servicio: RabitMQ como bus para encolar tareas largas y convertirlas en asyncronicas SignalR para notificar a los usuarios sobre la finalizaci\u00f3n de las tareas y como mensajer\u00eda Database para administrar los templates y los logs de interacci\u00f3n Templates Los templates se guardan en la base en la tabla Templates permiten definir desde el formato para el armado de un PDF hasta el env\u00edo de notificaciones por distintos canales: mails, sms, etc. Este es un ejemplo para insertar un template que permite la configuraci\u00f3n del env\u00edo de mails. El JsonDirective es un JSON con una interface que se usa depende del tipo de template que sea. Para el caso de los mails tiene la configuraci\u00f3n de con que se env\u00edan los mails, los datos est\u00e1ticos que se enviaran por mail y los par\u00e1metros a ser reemplazados en tiempo de ejecuci\u00f3n. Para el env\u00edo hay un endpoint que permite indicarle cu\u00e1l es el template (TemplateId) y cuales son los datos a ser reemplazados (diccionario con mapping con el objeto y donde va en el texto). De esta forma cuando alguien quiera enviar un mail deber\u00e1 inserta in registro en la base de datos con un nuevo TempateId y llamar al endpoint con los datos del objeto que ser\u00e1n reempalzados. Insertar un nuevo template Ejemplo para insertar en la base insert into templates (TemplateId, JsonDirective, [Module], Active ) values ('AUTH-CHECK-MAIL','{ \"MailSettings\": { \"MailServer\": \"email-smtp.us-east-1.amazonaws.com\", \"MailPort\": 587, \"Password\": \"\", \"UserName\": \"AKIASK5SMKGUXLBRWIAB\", \"SenderName\": \"GRAPE - Verificar Email\", \"Sender\": \"transaccional@grape.com.ar\", \"EnableSsl\": true }, \"MailMessage\": { \"Subject\": \"Verificaci\u00f3n de Email\", \"IsBodyHtml\": true, \"Body\": \"Estimado / a @identifier hemos generado un link para que verifique su Email < a href=@link>@link</a>.\" }, \"MailParameters\": { \"@identifier\": \"Identifier\", \"@link\": \"Link\" } }','AUTH',1) Env\u00edo de mails El env\u00edo de mails se realiza llamando al endpoint POST /api/jobs/{TempplateId}/from-template con el objeto a ser reemplazado en el BODY Ejemplo de llamada para el env\u00edo de mail ### Send mail from template POST {{host}}/mails/AUTH-CHECK-MAIL/from-template Content-Type: application/json Authorization: {{token}} { \"to\":\"fruiz@grape.com.ar\", \"Identifier\": \"Fernando Ruiz\", \"Link\": 6 }","title":"Microservicio Jobs"},{"location":"ms-jobs/#uso-del-microservicio-jobs-y-templates","text":"El microservicio Jobs tiene los siguientes servicio: RabitMQ como bus para encolar tareas largas y convertirlas en asyncronicas SignalR para notificar a los usuarios sobre la finalizaci\u00f3n de las tareas y como mensajer\u00eda Database para administrar los templates y los logs de interacci\u00f3n","title":"Uso del microservicio Jobs y templates"},{"location":"ms-jobs/#templates","text":"Los templates se guardan en la base en la tabla Templates permiten definir desde el formato para el armado de un PDF hasta el env\u00edo de notificaciones por distintos canales: mails, sms, etc. Este es un ejemplo para insertar un template que permite la configuraci\u00f3n del env\u00edo de mails. El JsonDirective es un JSON con una interface que se usa depende del tipo de template que sea. Para el caso de los mails tiene la configuraci\u00f3n de con que se env\u00edan los mails, los datos est\u00e1ticos que se enviaran por mail y los par\u00e1metros a ser reemplazados en tiempo de ejecuci\u00f3n. Para el env\u00edo hay un endpoint que permite indicarle cu\u00e1l es el template (TemplateId) y cuales son los datos a ser reemplazados (diccionario con mapping con el objeto y donde va en el texto). De esta forma cuando alguien quiera enviar un mail deber\u00e1 inserta in registro en la base de datos con un nuevo TempateId y llamar al endpoint con los datos del objeto que ser\u00e1n reempalzados.","title":"Templates"},{"location":"ms-jobs/#insertar-un-nuevo-template","text":"Ejemplo para insertar en la base insert into templates (TemplateId, JsonDirective, [Module], Active ) values ('AUTH-CHECK-MAIL','{ \"MailSettings\": { \"MailServer\": \"email-smtp.us-east-1.amazonaws.com\", \"MailPort\": 587, \"Password\": \"\", \"UserName\": \"AKIASK5SMKGUXLBRWIAB\", \"SenderName\": \"GRAPE - Verificar Email\", \"Sender\": \"transaccional@grape.com.ar\", \"EnableSsl\": true }, \"MailMessage\": { \"Subject\": \"Verificaci\u00f3n de Email\", \"IsBodyHtml\": true, \"Body\": \"Estimado / a @identifier hemos generado un link para que verifique su Email < a href=@link>@link</a>.\" }, \"MailParameters\": { \"@identifier\": \"Identifier\", \"@link\": \"Link\" } }','AUTH',1)","title":"Insertar un nuevo template"},{"location":"ms-jobs/#envio-de-mails","text":"El env\u00edo de mails se realiza llamando al endpoint POST /api/jobs/{TempplateId}/from-template con el objeto a ser reemplazado en el BODY Ejemplo de llamada para el env\u00edo de mail ### Send mail from template POST {{host}}/mails/AUTH-CHECK-MAIL/from-template Content-Type: application/json Authorization: {{token}} { \"to\":\"fruiz@grape.com.ar\", \"Identifier\": \"Fernando Ruiz\", \"Link\": 6 }","title":"Env\u00edo de mails"},{"location":"neox/","text":"Servicios Neox Recomendaciones para los desarrolladores Cuando trabajen con la base de datos deber\u00e1n mantener actualizado el proyecto de base de datos. Adem\u00e1s, dejar en una carpeta con la pr\u00f3xima versi\u00f3n un script dml, ddl donde est\u00e1n los scripts para ejecutar en todas las bases. Si hay alguna necesidad de correr alg\u00fan script que solo se ejecuta en una sola implementaci\u00f3n, se deber\u00e1 crear un archivo con el nombre del cliente o implementaci\u00f3n y dejar los cambios particulares. Clientes y ubicaciones Marquez es el \u00fanico que tiene su propio Tenant en AWS. Por ello para la actualizaci\u00f3n de la base de datos hay que conectarse a esa servicio. Y para lo que es microservicios y frontend tienen una maquina virtual. El resto de los clientes est\u00e1n en DB Azure y una maquina virtual en Azure. Todos los micro servicios y frontend est\u00e1n dockerizados. Publicaci\u00f3n en producci\u00f3n nueva versi\u00f3n Cuando se sube una versi\u00f3n nueva se sube para todas las implementaciones de Neox, NUNCA se deber\u00e1 subir en una sola implementaci\u00f3n. Las publicaciones constan de dos partes: Actualizaci\u00f3n de la base de datos. Estrucutras y datos. Integraci\u00f3n de los microservicios y frontend en las branch main. 1. Actualizaci\u00f3n de la base de datos A los desarrolladores que modifican estructuras de datos se les solicita dejar un script en una carpeta (\u00faltima versi\u00f3n) con los cambios que vayan haciendo para ejecutar los scripts de base de datos en todas las bases de datos. Adem\u00e1s, deber\u00e1n actualizar el proyecto de base de datos. A la hora de realizar la actualizaci\u00f3n se deber\u00eda correr el script y tener presente que si hay alg\u00fan script que solo deber\u00e1 ejecutarse en una sola de las bases de datos por cuestiones de configuraci\u00f3n deber\u00e1 existir el script propio de la implementaci\u00f3n, como por ej. marquez.sql. Por las dudas luego de ejecutar los scripts ejecuto desde el Azure Data Studio un Schema Compare del proyecto de base de datos contra cada una de las bases, es un procedimiento que no lleva m\u00e1s de 30 minutos pero en alguna oportunidad han aparecido faltantes en los script que dejan los desarrolladores. El procedimiento es el siguiente: Correr comparador proyecto contra cada base contra el proyecto abriendo el archivo loca-remote.scmp de la carpeta del proyecto de base de datos, comparar proyecto vs base neox Por cada base generar el script y verificarlo, hacer un replace de \"WITH NOCHECK\" por vacio Verificar y ejecutar script de la carpeta deploys a publicar https://github.com/neox-software/sql/pulls 2. Creaci\u00f3n de los Pulls de dev a main y merge Por \u00faltimo se deber\u00e1n realizar los merge de los Pulls de dev a prod que incluyen la versi\u00f3n. Es importante revisar que se est\u00e9n actualizando los n\u00fameros de las versiones de los microservicios, as\u00ed es f\u00e1cil de probarlos una vez desplegados con el /status de cada microservicio. Lo mismo con el frontend tiene que estar modificada la versi\u00f3n del archivo environment.prod.ts con la pr\u00f3xima. 1.XX agregando una a la anterior release. Una vez integrados los pulls los actions realizan el despliegue solos.","title":"Neox deploy"},{"location":"neox/#servicios-neox","text":"","title":"Servicios Neox"},{"location":"neox/#recomendaciones-para-los-desarrolladores","text":"Cuando trabajen con la base de datos deber\u00e1n mantener actualizado el proyecto de base de datos. Adem\u00e1s, dejar en una carpeta con la pr\u00f3xima versi\u00f3n un script dml, ddl donde est\u00e1n los scripts para ejecutar en todas las bases. Si hay alguna necesidad de correr alg\u00fan script que solo se ejecuta en una sola implementaci\u00f3n, se deber\u00e1 crear un archivo con el nombre del cliente o implementaci\u00f3n y dejar los cambios particulares.","title":"Recomendaciones para los desarrolladores"},{"location":"neox/#clientes-y-ubicaciones","text":"Marquez es el \u00fanico que tiene su propio Tenant en AWS. Por ello para la actualizaci\u00f3n de la base de datos hay que conectarse a esa servicio. Y para lo que es microservicios y frontend tienen una maquina virtual. El resto de los clientes est\u00e1n en DB Azure y una maquina virtual en Azure. Todos los micro servicios y frontend est\u00e1n dockerizados.","title":"Clientes y ubicaciones"},{"location":"neox/#publicacion-en-produccion-nueva-version","text":"Cuando se sube una versi\u00f3n nueva se sube para todas las implementaciones de Neox, NUNCA se deber\u00e1 subir en una sola implementaci\u00f3n. Las publicaciones constan de dos partes: Actualizaci\u00f3n de la base de datos. Estrucutras y datos. Integraci\u00f3n de los microservicios y frontend en las branch main.","title":"Publicaci\u00f3n en producci\u00f3n nueva versi\u00f3n"},{"location":"neox/#1-actualizacion-de-la-base-de-datos","text":"A los desarrolladores que modifican estructuras de datos se les solicita dejar un script en una carpeta (\u00faltima versi\u00f3n) con los cambios que vayan haciendo para ejecutar los scripts de base de datos en todas las bases de datos. Adem\u00e1s, deber\u00e1n actualizar el proyecto de base de datos. A la hora de realizar la actualizaci\u00f3n se deber\u00eda correr el script y tener presente que si hay alg\u00fan script que solo deber\u00e1 ejecutarse en una sola de las bases de datos por cuestiones de configuraci\u00f3n deber\u00e1 existir el script propio de la implementaci\u00f3n, como por ej. marquez.sql. Por las dudas luego de ejecutar los scripts ejecuto desde el Azure Data Studio un Schema Compare del proyecto de base de datos contra cada una de las bases, es un procedimiento que no lleva m\u00e1s de 30 minutos pero en alguna oportunidad han aparecido faltantes en los script que dejan los desarrolladores. El procedimiento es el siguiente: Correr comparador proyecto contra cada base contra el proyecto abriendo el archivo loca-remote.scmp de la carpeta del proyecto de base de datos, comparar proyecto vs base neox Por cada base generar el script y verificarlo, hacer un replace de \"WITH NOCHECK\" por vacio Verificar y ejecutar script de la carpeta deploys a publicar https://github.com/neox-software/sql/pulls","title":"1. Actualizaci\u00f3n de la base de datos"},{"location":"neox/#2-creacion-de-los-pulls-de-dev-a-main-y-merge","text":"Por \u00faltimo se deber\u00e1n realizar los merge de los Pulls de dev a prod que incluyen la versi\u00f3n. Es importante revisar que se est\u00e9n actualizando los n\u00fameros de las versiones de los microservicios, as\u00ed es f\u00e1cil de probarlos una vez desplegados con el /status de cada microservicio. Lo mismo con el frontend tiene que estar modificada la versi\u00f3n del archivo environment.prod.ts con la pr\u00f3xima. 1.XX agregando una a la anterior release. Una vez integrados los pulls los actions realizan el despliegue solos.","title":"2. Creaci\u00f3n de los Pulls de dev a main y merge"},{"location":"powerbi/","text":"Configuracion crear una cuenta que tenga asociada una licencia pro asignar en admin de office 365 los permisos de administrador de powerbi y power plataform ingresar al portal de azure con esa cuenta y registrar una nueva aplicaci\u00f3n en registro de aplicaciones asignar permisos a las API de power bi ingresar al portal de powerbi y validar en Portal de Administraci\u00f3n que este habilitado Conceder acceso a las APIs en Desarrollador Crear o modificar los workspace para darles acceso a la aplicaci\u00f3n registrada en azure (verificar el guid) Links Curso de powerbi embedded https://www.youtube.com/playlist?list=PLib8Q64STW-tCZVSvBAuEIzBsVlf0C81f https://blog.jpries.com/2020/01/03/getting-started-with-the-power-bi-api-querying-the-power-bi-rest-api-directly-with-c/ https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-service-principal https://learn.microsoft.com/en-us/power-bi/admin/service-admin-role?source=recommendations Permisos Se puede acceder para revisar desde el portal de azure -> Active Directory -> Registro de Aplicaciones -> Permisos de APIs El usuario con la cuenta pro debe tener establecido en roles de administrador: Administrador de PowerBI Administrador de Power Plataform Powerbi cli pbicli login --service-principal -p 25601d95-de48-4763-a36a-18df6f2805fb -s ZwE8Q~EEqhEjHLv88GCRP0m4Qsa2uQJVjH8BLaaD -t 465f9a2e-6e22-4169-938a-009fbbe36f1f pbicli report list --workspace 928fe4f4-2825-4162-8264-1410a653055f Change database https://community.powerbi.com/t5/Desktop/Power-BI-API-to-change-Database-dynamically/m-p/252013 https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-dynamic-binding","title":"Powerbi"},{"location":"powerbi/#configuracion","text":"crear una cuenta que tenga asociada una licencia pro asignar en admin de office 365 los permisos de administrador de powerbi y power plataform ingresar al portal de azure con esa cuenta y registrar una nueva aplicaci\u00f3n en registro de aplicaciones asignar permisos a las API de power bi ingresar al portal de powerbi y validar en Portal de Administraci\u00f3n que este habilitado Conceder acceso a las APIs en Desarrollador Crear o modificar los workspace para darles acceso a la aplicaci\u00f3n registrada en azure (verificar el guid)","title":"Configuracion"},{"location":"powerbi/#links","text":"Curso de powerbi embedded https://www.youtube.com/playlist?list=PLib8Q64STW-tCZVSvBAuEIzBsVlf0C81f https://blog.jpries.com/2020/01/03/getting-started-with-the-power-bi-api-querying-the-power-bi-rest-api-directly-with-c/ https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-service-principal https://learn.microsoft.com/en-us/power-bi/admin/service-admin-role?source=recommendations","title":"Links"},{"location":"powerbi/#permisos","text":"Se puede acceder para revisar desde el portal de azure -> Active Directory -> Registro de Aplicaciones -> Permisos de APIs El usuario con la cuenta pro debe tener establecido en roles de administrador: Administrador de PowerBI Administrador de Power Plataform","title":"Permisos"},{"location":"powerbi/#powerbi-cli","text":"pbicli login --service-principal -p 25601d95-de48-4763-a36a-18df6f2805fb -s ZwE8Q~EEqhEjHLv88GCRP0m4Qsa2uQJVjH8BLaaD -t 465f9a2e-6e22-4169-938a-009fbbe36f1f pbicli report list --workspace 928fe4f4-2825-4162-8264-1410a653055f","title":"Powerbi cli"},{"location":"powerbi/#change-database","text":"https://community.powerbi.com/t5/Desktop/Power-BI-API-to-change-Database-dynamically/m-p/252013 https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-dynamic-binding","title":"Change database"},{"location":"schema-compare/","text":"Schema compare Las opciones se pueden guardar en un archivo scmp para poder recuperarlas luega y hacer siempre las mismas comparaciones. Queda resolver la opci\u00f3n que tiene dbArt Settings Set Ignore With NoCheck uncheck Script New Contraint Validation Uncheck all Drop XXXX Not In Source Check Ignore Column Order","title":"Schema Compare"},{"location":"schema-compare/#schema-compare","text":"Las opciones se pueden guardar en un archivo scmp para poder recuperarlas luega y hacer siempre las mismas comparaciones. Queda resolver la opci\u00f3n que tiene dbArt","title":"Schema compare"},{"location":"schema-compare/#settings","text":"Set Ignore With NoCheck uncheck Script New Contraint Validation Uncheck all Drop XXXX Not In Source Check Ignore Column Order","title":"Settings"},{"location":"semantic-release/","text":"Grape use of Semantic Release All developers should use this specifications. Project specifications C# backend projects In .csproj this code should be defined in <VersionPrefix>1.0.0</VersionPrefix> <VersionSuffix>$([System.DateTime]::UtcNow.ToString(`yyyyMMdd-HHmm`))</VersionSuffix> ``` Manually versioning Angular In environments add version: '1.0.0', Add in .ts file: version: string = '1.0'; year = 0; custom = { version: true, }; constructor() {} ngOnInit(): void { this.version = environment.version; this.year = new Date().getFullYear(); } Add in html file: <p class=\"mb-1\">\u00a9 {{ year }} AppName v.{{ version }}</p>","title":"Releasing"},{"location":"semantic-release/#grape-use-of-semantic-release","text":"All developers should use this specifications.","title":"Grape use of Semantic Release"},{"location":"semantic-release/#project-specifications","text":"","title":"Project specifications"},{"location":"semantic-release/#c-backend-projects","text":"In .csproj this code should be defined in <VersionPrefix>1.0.0</VersionPrefix> <VersionSuffix>$([System.DateTime]::UtcNow.ToString(`yyyyMMdd-HHmm`))</VersionSuffix> ```","title":"C# backend projects"},{"location":"semantic-release/#manually-versioning-angular","text":"In environments add version: '1.0.0', Add in .ts file: version: string = '1.0'; year = 0; custom = { version: true, }; constructor() {} ngOnInit(): void { this.version = environment.version; this.year = new Date().getFullYear(); } Add in html file: <p class=\"mb-1\">\u00a9 {{ year }} AppName v.{{ version }}</p>","title":"Manually versioning Angular"},{"location":"videos/","text":"Videos instructivos Como trabajar en el proceso productivo de Grape usando Snippets C# creaci\u00f3n de cruds usando snippets Part 1 Controller y search https://techmindarg-my.sharepoint.com/:v:/g/personal/fruiz_grape_com_ar/EWOkNDWsv2lDnYDLDPp7UTYBtatL8Okhsz4B0tF4BcJkoA?e=llO2Yb Parte 2 POST, PUT, DELETE https://techmindarg-my.sharepoint.com/:v:/g/personal/fruiz_grape_com_ar/EdcgApih0K5Ilf7dJ2cmDXUBoZUABjsIixuYwouAqBhs7Q?e=m2GzFW","title":"Videos snippets"},{"location":"videos/#videos-instructivos","text":"Como trabajar en el proceso productivo de Grape usando Snippets","title":"Videos instructivos"},{"location":"videos/#c-creacion-de-cruds-usando-snippets","text":"Part 1 Controller y search https://techmindarg-my.sharepoint.com/:v:/g/personal/fruiz_grape_com_ar/EWOkNDWsv2lDnYDLDPp7UTYBtatL8Okhsz4B0tF4BcJkoA?e=llO2Yb Parte 2 POST, PUT, DELETE https://techmindarg-my.sharepoint.com/:v:/g/personal/fruiz_grape_com_ar/EdcgApih0K5Ilf7dJ2cmDXUBoZUABjsIixuYwouAqBhs7Q?e=m2GzFW","title":"C# creaci\u00f3n de cruds usando snippets"},{"location":"working/","text":"Working on Grape Projects On boarding to dev team Before a dev can work with Grape Projects should be enable in our Tools. For that reason we need to send and email to admin@grape.com.ar with the following information: Mail to add in Dev Ops Github Account to add in repos Sign NDA Defines role in Dev Team (Frontend, Mobile, Backend, UX Designer or Full stack) Tools we use We use Azure DevOps Boards for daily task, user stories or features, It's help us to define priorities on all differents projects. Our source code is in Github private repos. We have differents Organizations for main projects or customers and inside each Organization we work on his specific repos. We code mainly with vs code and azure data studio. Also, in some cases we use visual studio for older project in asp.net or wpf for windows. Task Assignation We usually meet daily in the morning to assign task and define priorities for a day or two. Task are assingned in DevOps with estimated hours, if for some reason task is taking more than estimation time developer should notify user story responsable and wait for an answer working in another task. When description of task is confuse or incomplete dev could start a work item discussion with user story responsable or other team member to clarify. Once a dev has correct specification and task understanding must activate task so others team members knows this task is taken. To start working in code dev should start a branch asociated with is user, work item id and some short description. ie: fruizar/144-improve-import. Mainly base branch colud be dev but in some cases when a fix is needed on production environment main o master branch should be use as base, in that case PR should be done to main and dev. Submitting and Closing Tasks After task is done following Coding standarizations and good practices dev should close task indicating Completed time hours in work item. If some consideration about task execution is needed dev should write it in work item discussion. Dev also need to make a pull request in Github indication who must Review the code, usually is user story responsable or team leader. In PR description Work item URL should be write and other considerations dev wants to tell reviewer. Code standarization Grape has snippets for most common user stories on differents languages, dev should install it from https://github.com/grape-software/docs/tree/main/snippets and use it when starting a standar task. Dev could improve this snippets modyfing or adding new ones, all should start with gr-en-DESCRIPTION, making a Pull Request in docs repository. Standard Angular UI Search Module Is used like a menu where user can work with some part of business making most common operations: Search with filters or advances filters Add, edit or remove Export or Import Defines record by page Order results Access to related lists View resume information en footer Make some business specific actions Add or edit operations could be on Popup, when little inputs needs to be fill, or with navigation in other case. Remove operations are confirmed in Popup in same search screen. Asociated Lists User access some part of business throw search module and then needs to work with related records ie. Headers and Details objects. This UI try to solve operations related with asociated list of object business. User could: View Header with Parent Record Resume Information and back icon See paged list Defines record by page Order results Add, edit or remove Make some business specific actions Add, edit and remove operations are in Popup in this UI unless specified differently in the task. CU Components Create or Update Components are Form Angular components that allows to add or edit a database record in some cases with a complex transaction that writes in multiple entities. Must have client simple domain logic validation for each input. ie. max, number, dates, select validations. Raising user friendly backend messages. Stepper UI Stepper allows complex transactions to be made in simple steps for the user and send a whole transactions POST to backend. Step component could be in own stepper or a reusing existing component. Automplete Each time a user needs to select a record with a big number of records or with multi attributes to look for should be implemented as a autocomplete component for reuse. This component has only input in html and binding a calculate field calls fullName implemented in Class to search for as Not Mapped. Standard Backend CRUD operations SEARCH Allows to make searchs for Search UI with common filters implemented in searchText, custom based specific attribute for custom SearchX class inherited from SearchModel. Set number of records for page and order by any object attribute. Implements onlyActive attribute to get active records in each business model. Returns a dynamic object with totalCount with all records, res array with a list of business object to search for and a search object with all attributes passed to search API. API is /{controller} C# Snippet gr-en-search GET Allows to make a get for an specific business object with all his first level related entities and in some cases including more than first level. Returns all attributes of business object with included entities. API is /{controller}/{id} C# Snippet gr-en-get-id POST Allows to make a call to insert a record o a record with related in one transaction to the database. All business validation to get consistency should be done in this method. C# Snippet gr-en-post PUT Allows to make a call to insert a record o a record with related in one transaction to the database. All business validation to get consistency should be done in this method. Working with Audits component changes should be done with db.Entry(oldObject).CurrentValues.SetValues(record); C# Snippet gr-en-put DELETE Deletes remove entity from database, some business use cases should implement logical deleted with an database update instead phisically delete record. In some cases it must record to trash table whole object in json format. C# Sinppet gr-en-delete AUTOCOMPLETE Search in database for automplete typeahead input objects and should returns fullName (calculated not mapped field) and business primary key. C# Snippet gr-en-autocomplete Coding good practices API Comments Should explain what API does and what validation it have. Swagger All public method should be marked as [ApiExplorerSettings(IgnoreApi = true)] to work with swagger. Before push code backend /docs must be checked in order to validate OpenAPI docs is working. Vs Code Configuration C Format on Save Lint? Extensions: Omnisharp C# C# xml Documentation Comments (Keisuke Kato) RestClient (Huachao Mao) Angular Format on Save Extensions: Angular Essentials (Jhon Papa) Angular Lanfuage Service Prettier ESLint sort-imports (VSC Sort Import) Commit Message Format https://github.com/angular/angular/blob/master/CONTRIBUTING.md#-commit-message-format This specification is inspired by and supersedes the [AngularJS commit message format][commit-message-format]. We have very precise rules over how our Git commit messages must be formatted. This format leads to easier to read commit history . Each commit message consists of a header , a body , and a footer . <header> <BLANK LINE> <body> <BLANK LINE> <footer> The header is mandatory and must conform to the Commit Message Header format. The body is mandatory for all commits except for those of type \"docs\". When the body is present it must be at least 20 characters long and must conform to the Commit Message Body format. The footer is optional. The Commit Message Footer format describes what the footer is used for and the structure it must have. Commit Message Header <type>(<scope>): <short summary> \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2af8 Summary in present tense. Not capitalized. No period at the end. \u2502 \u2502 \u2502 \u2514\u2500\u2af8 Commit Scope: animations|bazel|benchpress|common|compiler|compiler-cli|core| \u2502 elements|forms|http|language-service|localize|platform-browser| \u2502 platform-browser-dynamic|platform-server|router|service-worker| \u2502 upgrade|zone.js|packaging|changelog|docs-infra|migrations|ngcc|ve| \u2502 devtools \u2502 \u2514\u2500\u2af8 Commit Type: build|ci|docs|feat|fix|perf|refactor|test The <type> and <summary> fields are mandatory, the (<scope>) field is optional. Type Must be one of the following: build : Changes that affect the build system or external dependencies (example scopes: gulp, broccoli, npm) ci : Changes to our CI configuration files and scripts (examples: CircleCi, SauceLabs) docs : Documentation only changes feat : A new feature fix : A bug fix perf : A code change that improves performance refactor : A code change that neither fixes a bug nor adds a feature test : Adding missing tests or correcting existing tests","title":"Working"},{"location":"working/#working-on-grape-projects","text":"","title":"Working on Grape Projects"},{"location":"working/#on-boarding-to-dev-team","text":"Before a dev can work with Grape Projects should be enable in our Tools. For that reason we need to send and email to admin@grape.com.ar with the following information: Mail to add in Dev Ops Github Account to add in repos Sign NDA Defines role in Dev Team (Frontend, Mobile, Backend, UX Designer or Full stack)","title":"On boarding to dev team"},{"location":"working/#tools-we-use","text":"We use Azure DevOps Boards for daily task, user stories or features, It's help us to define priorities on all differents projects. Our source code is in Github private repos. We have differents Organizations for main projects or customers and inside each Organization we work on his specific repos. We code mainly with vs code and azure data studio. Also, in some cases we use visual studio for older project in asp.net or wpf for windows.","title":"Tools we use"},{"location":"working/#task-assignation","text":"We usually meet daily in the morning to assign task and define priorities for a day or two. Task are assingned in DevOps with estimated hours, if for some reason task is taking more than estimation time developer should notify user story responsable and wait for an answer working in another task. When description of task is confuse or incomplete dev could start a work item discussion with user story responsable or other team member to clarify. Once a dev has correct specification and task understanding must activate task so others team members knows this task is taken. To start working in code dev should start a branch asociated with is user, work item id and some short description. ie: fruizar/144-improve-import. Mainly base branch colud be dev but in some cases when a fix is needed on production environment main o master branch should be use as base, in that case PR should be done to main and dev.","title":"Task Assignation"},{"location":"working/#submitting-and-closing-tasks","text":"After task is done following Coding standarizations and good practices dev should close task indicating Completed time hours in work item. If some consideration about task execution is needed dev should write it in work item discussion. Dev also need to make a pull request in Github indication who must Review the code, usually is user story responsable or team leader. In PR description Work item URL should be write and other considerations dev wants to tell reviewer.","title":"Submitting and Closing Tasks"},{"location":"working/#code-standarization","text":"Grape has snippets for most common user stories on differents languages, dev should install it from https://github.com/grape-software/docs/tree/main/snippets and use it when starting a standar task. Dev could improve this snippets modyfing or adding new ones, all should start with gr-en-DESCRIPTION, making a Pull Request in docs repository.","title":"Code standarization"},{"location":"working/#standard-angular-ui","text":"","title":"Standard Angular UI"},{"location":"working/#search-module","text":"Is used like a menu where user can work with some part of business making most common operations: Search with filters or advances filters Add, edit or remove Export or Import Defines record by page Order results Access to related lists View resume information en footer Make some business specific actions Add or edit operations could be on Popup, when little inputs needs to be fill, or with navigation in other case. Remove operations are confirmed in Popup in same search screen.","title":"Search Module"},{"location":"working/#asociated-lists","text":"User access some part of business throw search module and then needs to work with related records ie. Headers and Details objects. This UI try to solve operations related with asociated list of object business. User could: View Header with Parent Record Resume Information and back icon See paged list Defines record by page Order results Add, edit or remove Make some business specific actions Add, edit and remove operations are in Popup in this UI unless specified differently in the task.","title":"Asociated Lists"},{"location":"working/#cu-components","text":"Create or Update Components are Form Angular components that allows to add or edit a database record in some cases with a complex transaction that writes in multiple entities. Must have client simple domain logic validation for each input. ie. max, number, dates, select validations. Raising user friendly backend messages.","title":"CU Components"},{"location":"working/#stepper-ui","text":"Stepper allows complex transactions to be made in simple steps for the user and send a whole transactions POST to backend. Step component could be in own stepper or a reusing existing component.","title":"Stepper UI"},{"location":"working/#automplete","text":"Each time a user needs to select a record with a big number of records or with multi attributes to look for should be implemented as a autocomplete component for reuse. This component has only input in html and binding a calculate field calls fullName implemented in Class to search for as Not Mapped.","title":"Automplete"},{"location":"working/#standard-backend-crud-operations","text":"","title":"Standard Backend CRUD operations"},{"location":"working/#search","text":"Allows to make searchs for Search UI with common filters implemented in searchText, custom based specific attribute for custom SearchX class inherited from SearchModel. Set number of records for page and order by any object attribute. Implements onlyActive attribute to get active records in each business model. Returns a dynamic object with totalCount with all records, res array with a list of business object to search for and a search object with all attributes passed to search API. API is /{controller} C# Snippet gr-en-search","title":"SEARCH"},{"location":"working/#get","text":"Allows to make a get for an specific business object with all his first level related entities and in some cases including more than first level. Returns all attributes of business object with included entities. API is /{controller}/{id} C# Snippet gr-en-get-id","title":"GET"},{"location":"working/#post","text":"Allows to make a call to insert a record o a record with related in one transaction to the database. All business validation to get consistency should be done in this method. C# Snippet gr-en-post","title":"POST"},{"location":"working/#put","text":"Allows to make a call to insert a record o a record with related in one transaction to the database. All business validation to get consistency should be done in this method. Working with Audits component changes should be done with db.Entry(oldObject).CurrentValues.SetValues(record); C# Snippet gr-en-put","title":"PUT"},{"location":"working/#delete","text":"Deletes remove entity from database, some business use cases should implement logical deleted with an database update instead phisically delete record. In some cases it must record to trash table whole object in json format. C# Sinppet gr-en-delete","title":"DELETE"},{"location":"working/#autocomplete","text":"Search in database for automplete typeahead input objects and should returns fullName (calculated not mapped field) and business primary key. C# Snippet gr-en-autocomplete","title":"AUTOCOMPLETE"},{"location":"working/#coding-good-practices","text":"","title":"Coding good practices"},{"location":"working/#api-comments","text":"Should explain what API does and what validation it have.","title":"API Comments"},{"location":"working/#swagger","text":"All public method should be marked as [ApiExplorerSettings(IgnoreApi = true)] to work with swagger. Before push code backend /docs must be checked in order to validate OpenAPI docs is working.","title":"Swagger"},{"location":"working/#vs-code-configuration","text":"","title":"Vs Code Configuration"},{"location":"working/#c","text":"Format on Save Lint? Extensions: Omnisharp C# C# xml Documentation Comments (Keisuke Kato) RestClient (Huachao Mao)","title":"C"},{"location":"working/#angular","text":"Format on Save Extensions: Angular Essentials (Jhon Papa) Angular Lanfuage Service Prettier ESLint sort-imports (VSC Sort Import)","title":"Angular"},{"location":"working/#commit-message-format","text":"https://github.com/angular/angular/blob/master/CONTRIBUTING.md#-commit-message-format This specification is inspired by and supersedes the [AngularJS commit message format][commit-message-format]. We have very precise rules over how our Git commit messages must be formatted. This format leads to easier to read commit history . Each commit message consists of a header , a body , and a footer . <header> <BLANK LINE> <body> <BLANK LINE> <footer> The header is mandatory and must conform to the Commit Message Header format. The body is mandatory for all commits except for those of type \"docs\". When the body is present it must be at least 20 characters long and must conform to the Commit Message Body format. The footer is optional. The Commit Message Footer format describes what the footer is used for and the structure it must have.","title":" Commit Message Format"},{"location":"working/#commit-message-header","text":"<type>(<scope>): <short summary> \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2af8 Summary in present tense. Not capitalized. No period at the end. \u2502 \u2502 \u2502 \u2514\u2500\u2af8 Commit Scope: animations|bazel|benchpress|common|compiler|compiler-cli|core| \u2502 elements|forms|http|language-service|localize|platform-browser| \u2502 platform-browser-dynamic|platform-server|router|service-worker| \u2502 upgrade|zone.js|packaging|changelog|docs-infra|migrations|ngcc|ve| \u2502 devtools \u2502 \u2514\u2500\u2af8 Commit Type: build|ci|docs|feat|fix|perf|refactor|test The <type> and <summary> fields are mandatory, the (<scope>) field is optional.","title":"Commit Message Header"},{"location":"working/#type","text":"Must be one of the following: build : Changes that affect the build system or external dependencies (example scopes: gulp, broccoli, npm) ci : Changes to our CI configuration files and scripts (examples: CircleCi, SauceLabs) docs : Documentation only changes feat : A new feature fix : A bug fix perf : A code change that improves performance refactor : A code change that neither fixes a bug nor adds a feature test : Adding missing tests or correcting existing tests","title":"Type"}]}